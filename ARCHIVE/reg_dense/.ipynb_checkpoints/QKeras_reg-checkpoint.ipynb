{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QKeras dense layer comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, LSTM, GRU, SimpleRNN, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import qkeras\n",
    "from qkeras import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a simple dataset using numpy\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "y = np.sin(5*x)\n",
    "\n",
    "x_val = np.linspace(-1, 1, 100)\n",
    "y_val = np.sin(5*x_val)\n",
    "\n",
    "x_test = np.linspace(-1, 1, 1000)\n",
    "y_test = np.sin(5*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inputs/outputs.txt\", \"w\") as inputs_file :\n",
    "    for i in range(1000):\n",
    "        save_inputs = str(float(y[i]))\n",
    "        inputs_file.write(\"{}\\n\".format(save_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 14:27:26.966475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-13 14:27:26.966491: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-13 14:27:26.966520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marsattack3): /proc/driver/nvidia/version does not exist\n",
      "2022-04-13 14:27:26.967022: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4576 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4269 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.3977 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 976us/step - loss: 0.3855 - val_loss: 0.3704 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3449 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3204 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.2970 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.2745 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.2524 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2442 - val_loss: 0.2312 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 990us/step - loss: 0.2231 - val_loss: 0.2103 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.2025 - val_loss: 0.1906 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 954us/step - loss: 0.1827 - val_loss: 0.1713 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1533 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1371 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 976us/step - loss: 0.1302 - val_loss: 0.1211 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 994us/step - loss: 0.1152 - val_loss: 0.1074 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1014 - val_loss: 0.0947 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0830 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0730 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0643 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0566 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.0501 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0442 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0397 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0351 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.0315 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.0291 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0260 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0238 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0222 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 788us/step - loss: 0.0204 - val_loss: 0.0202 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0190 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0185 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0168 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0154 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.0143 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0137 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 638us/step - loss: 0.0117 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 974us/step - loss: 0.0112 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0120 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 972us/step - loss: 0.0112 - val_loss: 0.0119 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 619us/step - loss: 0.0106 - val_loss: 0.0123 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 953us/step - loss: 0.0106 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0116 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab2eb258d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = 1\n",
    "\n",
    "checkpoint_filepath = '/atlas/bonnet/tmp/model_checkpoint'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='val_loss',\n",
    "                                                                mode='min',\n",
    "                                                                save_best_only=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "d_model = Sequential()\n",
    "\n",
    "d_model.add(Dense(10,input_dim= 1, activation='relu'))\n",
    "d_model.add(Dense(output, activation='linear'))\n",
    "\n",
    "d_model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
    "d_model.summary()\n",
    "\n",
    "d_model.fit(x, y, validation_data= (x_val,y_val), epochs=50, batch_size=10, callbacks=[reduce_lr,model_checkpoint_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantized network, saving weights function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 1\n",
    "\n",
    "\n",
    "def quantized_model (bits, original_weights):\n",
    "    qcheckpoint_filepath = '/atlas/bonnet/tmp/qmodel_checkpoint'\n",
    "    qmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=qcheckpoint_filepath,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_loss',\n",
    "                                                                    mode='min',\n",
    "                                                                    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    qd_model = Sequential()\n",
    "    qd_model.add(QDense(10,\n",
    "                        input_dim= 1,   \n",
    "                        activation='relu', \n",
    "                        kernel_quantizer=quantized_bits(*bits),\n",
    "                        bias_quantizer=quantized_bits(*bits)))\n",
    "\n",
    "    qd_model.add(QDense(output, \n",
    "                        activation='linear',\n",
    "                        kernel_quantizer=quantized_bits(*bits),\n",
    "                        bias_quantizer=quantized_bits(*bits)))\n",
    "\n",
    "    qd_model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "    qd_model.summary()\n",
    "    #using the weight from the classic network as a base\n",
    "    qd_model.set_weights(original_weights.get_weights())\n",
    "    qd_model.fit(x, y, validation_data= (x_val,y_val),epochs = 50, callbacks=[qmodel_checkpoint_callback,reduce_lr])\n",
    "    qd_model.load_weights(qcheckpoint_filepath)\n",
    "\n",
    "    return qd_model\n",
    "\n",
    "def model_saving (): \n",
    "    models =[]\n",
    "    for i in range(8):\n",
    "        bits_parameter = ((i+4)*2, 4, 0, 1)\n",
    "\n",
    "        models.append( quantized_model(bits_parameter, d_model))\n",
    "        \n",
    "        # In case we want to extract weights layer by layer\n",
    "        \"\"\"\n",
    "        for layer in  quantized_model(bits_parameter).layers:\n",
    "            weights = weights + layer.get_weights()\n",
    "            print ('bits parameter =', bits_parameter,'weights = ', weights)\n",
    "        \"\"\"\n",
    "        \n",
    "    return models\n",
    "        \n",
    "qmodels = model_saving()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n",
      "... quantizing model\n"
     ]
    }
   ],
   "source": [
    "#saving and storing the quantized model\n",
    "for i, q in enumerate(qmodels):\n",
    "    q.save(f'qmodels/models/qmodel{i}.h5')\n",
    "\n",
    "#saving and storing the weights of the quantized model\n",
    "\n",
    "q_weights = []\n",
    "\n",
    "for i, q in enumerate(qmodels):  #storing them into an array\n",
    "    q_weights.append(qkeras.utils.model_save_quantized_weights(q))\n",
    "\n",
    "\n",
    "for i, q in enumerate(qmodels): #saving them\n",
    "    qkeras.utils.model_save_quantized_weights(q,f'qmodels/weights/qmodel_weights{i}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.859375  , -0.9609375 , -0.9921875 , -0.96875   , -0.9296875 ,\n",
       "          0.9921875 , -1.984375  , -0.49609375, -0.8359375 ,  0.9921875 ]],\n",
       "       dtype=float32),\n",
       " array([-0.25 , -0.25 , -0.375, -0.375, -0.25 , -0.375,  0.5  , -0.125,\n",
       "        -0.25 , -0.5  ], dtype=float32),\n",
       " array([[-1.53125 ],\n",
       "        [ 1.21875 ],\n",
       "        [ 0.984375],\n",
       "        [ 1.53125 ],\n",
       "        [ 1.421875],\n",
       "        [-1.09375 ],\n",
       "        [-1.8125  ],\n",
       "        [ 1.96875 ],\n",
       "        [ 1.515625],\n",
       "        [-0.984375]], dtype=float32),\n",
       " array([0.875], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodels[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the classic model with 'manually' quantized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fab242f4d90>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7fab2e6cdfd0>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7fab2e5b7890>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7fab2ec53150>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7fab24190090>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7faaf43512d0>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7faac06abad0>\n",
      "Saved model to disk\n",
      "<keras.engine.sequential.Sequential object at 0x7faab873a090>\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "config = d_model.get_config()\n",
    "tmp_model = Sequential().from_config(config)\n",
    "\n",
    "\n",
    "for i, w in enumerate(qmodels) :\n",
    "    print(w)\n",
    "    \n",
    "    #taking the quantized weight and pass them into a quantizer previously used in order to \n",
    "    #'keep them quantized' even after they have been stored \n",
    "    tmp_model.set_weights([w.layers[0].kernel_quantizer(n) for n in w.get_weights()])\n",
    "\n",
    "    #storing the model into json and and h5\n",
    "    model_json = tmp_model.to_json()\n",
    "    with open(f\"models/model{i}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    tmp_model.save_weights(f\"models/model{i}.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.859375  , -0.9609375 , -0.9921875 , -0.96875   , -0.9296875 ,\n",
      "         0.9921875 , -1.984375  , -0.49609375, -0.8359375 ,  0.9921875 ]],\n",
      "      dtype=float32), array([-0.25 , -0.25 , -0.375, -0.375, -0.25 , -0.375,  0.5  , -0.125,\n",
      "       -0.25 , -0.5  ], dtype=float32), array([[-1.53125 ],\n",
      "       [ 1.21875 ],\n",
      "       [ 0.984375],\n",
      "       [ 1.53125 ],\n",
      "       [ 1.421875],\n",
      "       [-1.09375 ],\n",
      "       [-1.8125  ],\n",
      "       [ 1.96875 ],\n",
      "       [ 1.515625],\n",
      "       [-0.984375]], dtype=float32), array([0.875], dtype=float32)]\n",
      "[array([[ 0.859375  , -0.9609375 , -0.9921875 , -0.96875   , -0.9296875 ,\n",
      "         0.9921875 , -1.984375  , -0.49609375, -0.8359375 ,  0.9921875 ]],\n",
      "      dtype=float32), array([-0.25      , -0.25      , -0.375     , -0.375     , -0.25      ,\n",
      "       -0.375     ,  0.49609375, -0.125     , -0.25      , -0.49609375],\n",
      "      dtype=float32), array([[-1.53125 ],\n",
      "       [ 1.21875 ],\n",
      "       [ 0.984375],\n",
      "       [ 1.53125 ],\n",
      "       [ 1.421875],\n",
      "       [-1.09375 ],\n",
      "       [-1.8125  ],\n",
      "       [ 1.96875 ],\n",
      "       [ 1.515625],\n",
      "       [-0.984375]], dtype=float32), array([0.875], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "qm = qkeras.utils.load_qmodel('qmodels/models/qmodel0.h5' )\n",
    "qm.load_weights('qmodels/weights/qmodel_weights0.h5')\n",
    "print(qm.get_weights())\n",
    "\n",
    "qm.load_weights('models/model0.h5')\n",
    "print(qm.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS4ML CONVERSION PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/hls4ml-0.5.1-py3.7.egg/hls4ml/converters/__init__.py:15: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: dense_input, layer type: Input\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(d_model, granularity='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': 'ap_fixed<16,6>',\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency'},\n",
       " 'LayerName': {'dense_input': {'Precision': {'result': 'ap_fixed<16,6>'}},\n",
       "  'dense': {'Precision': {'weight': 'ap_fixed<16,6>',\n",
       "    'bias': 'ap_fixed<16,6>',\n",
       "    'result': 'ap_fixed<16,6>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'dense_relu': {'Precision': 'ap_fixed<16,6>',\n",
       "   'ReuseFactor': 1,\n",
       "   'table_size': 1024,\n",
       "   'table_t': 'ap_fixed<18,8>'},\n",
       "  'dense_1': {'Precision': {'weight': 'ap_fixed<16,6>',\n",
       "    'bias': 'ap_fixed<16,6>',\n",
       "    'result': 'ap_fixed<16,6>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'dense_1_linear': {'Precision': 'ap_fixed<16,6>',\n",
       "   'ReuseFactor': 1,\n",
       "   'table_size': 1024,\n",
       "   'table_t': 'ap_fixed<18,8>'}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'dense_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, 'dense': {'Precision': {'weight': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, 'dense_1': {'Precision': {'weight': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_1_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}}}\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: dense_input, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 1]], output shape: [None, 10]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/inteltools/altera/21.1.0.169.pro/gcc/bin/ld: myproject.o: relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC\n",
      "/inteltools/altera/21.1.0.169.pro/gcc/bin/ld: myproject_bridge.o: relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC\n",
      "/inteltools/altera/21.1.0.169.pro/gcc/bin/ld: myproject_bridge.o: warning: relocation against `_ZN4nnet13trace_outputsB5cxx11E' in read-only section `.text'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "models/hls_models/firmware/myproject-7bB585EA.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28138/3122046786.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                        \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models/hls_models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                        part='1SG280HU2F50E2VG', backend='Quartus')\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_qkeras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/hls4ml-0.5.1-py3.7.egg/hls4ml/model/graph.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_top_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: models/hls_models/firmware/myproject-7bB585EA.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------\")\n",
    "print (config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(d_model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='models/hls_models',\n",
    "                                                       part='1SG280HU2F50E2VG', backend='Quartus')\n",
    "hls_model.compile()\n",
    "\n",
    "y_qkeras = d_model.predict(x_test)\n",
    "y_hls = hls_model.predict(x_test.reshape(x_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "874925f81c3828312169ebb1df48ecaf2ae75230b67d0463fa32a76876fbeb18"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
