{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/02\n",
      "uproot version: 4.2.3\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "This script dumps NN results to a TTree that is read by the plotting script\n",
    "\n",
    "Usage:\n",
    "import nnDumper_standalone\n",
    "\n",
    "dump_preds = nnDumper_standalonedumper(start = int(data.shape[0]*(training_set+v_set)), name = \"test_out\")\n",
    "\n",
    "dump_preds.set_data(true = hit*16, data = dig*16, sig = sig*16, ofmax = np.concatenate([i['sequence_OFMax_eT'] for i in dataset]))\n",
    "\n",
    "dump_preds.set_preds('lstm_merge', 16*model.predict([X_test,X_peak_test]).flatten())\n",
    "dump_preds.set_preds('lstm_seq5', 16*old_model.predict(X_test).flatten())\n",
    "\n",
    "dump_preds.runme()\n",
    "\n",
    "\"\"\"\n",
    "# General packages\n",
    "import ROOT\n",
    "import numpy as np\n",
    "\n",
    "# Analysis in root and plotting setup\n",
    "import uproot  # root\n",
    "print(\"uproot version:\", uproot.__version__)\n",
    "if str(uproot.__version__)[0] == 3:\n",
    "    print(\"update your uproot to uproot4\")\n",
    "#import uproot_methods.classes.TH1 as uproot_TH1\n",
    "\n",
    "\n",
    "class Cfg:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.asdf = None\n",
    "\n",
    "\n",
    "class dumper:\n",
    "    \"\"\" collect NN results and dump in root file\n",
    "    \"\"\"\n",
    "\n",
    "    # , cfg=None, datacollection=None) :\n",
    "    def __init__(self, start, name, threshold=0.24, bt_len=80):\n",
    "        #self.cfg = config.globalconfig() if cfg is None else cfg\n",
    "        # ## this root data will be writen as output\n",
    "\n",
    "        self.name = name\n",
    "        self.cfg = Cfg()\n",
    "        self.start = start\n",
    "\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.rootData = None  # rootData(cfg=self.cfg)\n",
    "        # ## data to save\n",
    "        # # np.arrays of the relevant add-ons\n",
    "        self.bcid = None\n",
    "        self.ofmax = None\n",
    "        self.edepo = None\n",
    "        self.adc = None\n",
    "\n",
    "        # add the signal and the gap to previous signal\n",
    "        self.sig = None\n",
    "        self.gap = None\n",
    "        self.gap_for_all_bcs = None\n",
    "        self.bunchtrain_position = None\n",
    "        self.bt_len = bt_len\n",
    "\n",
    "        # # dict {Id : np.array()} for NN predictions\n",
    "        self.preds = {}\n",
    "        # # th1 store\n",
    "        self.histowner = set()\n",
    "\n",
    "    def set_data(self, true, data, sig, ofmax):\n",
    "\n",
    "        self.ofmax = ofmax\n",
    "        self.edepo = true\n",
    "        self.adc = data\n",
    "        self.sig = sig\n",
    "\n",
    "        self.bcid = np.array([i for i in range(len(self.adc))])\n",
    "\n",
    "    def set_preds(self, name, pred):\n",
    "\n",
    "        self.add_prediction(name, pred)\n",
    "\n",
    "    def get_gap_to_previous(self):\n",
    "\n",
    "        self.gap = np.zeros_like(self.sig)\n",
    "        dist_to_prev = 0\n",
    "\n",
    "        for i in range(0, len(self.edepo)):\n",
    "            dist_to_prev += 1\n",
    "\n",
    "            if self.edepo[i] > self.threshold:\n",
    "                self.gap[i] = dist_to_prev\n",
    "                dist_to_prev = 0\n",
    "\n",
    "    def get_gap_to_previous_for_all_bcs(self):\n",
    "\n",
    "        self.gap_for_all_bcs = np.zeros_like(self.sig)\n",
    "        dist_to_prev = 0\n",
    "\n",
    "        for i in range(0, len(self.edepo)):\n",
    "            dist_to_prev += 1\n",
    "            self.gap_for_all_bcs[i] = dist_to_prev\n",
    "\n",
    "            if self.edepo[i] > self.threshold:\n",
    "                dist_to_prev = 0\n",
    "\n",
    "    def get_bunchtrain(self):\n",
    "\n",
    "        self.bunchtrain_position = np.zeros_like(self.edepo)\n",
    "\n",
    "        for i in range(0, self.edepo.shape[0], self.bt_len):\n",
    "            if self.edepo.shape[0] - i < self.bt_len:\n",
    "                asdf = self.edepo.shape[0] - i\n",
    "                self.bunchtrain_position[i:] = np.arange(1, asdf + 1)\n",
    "            else:\n",
    "                self.bunchtrain_position[i:i +\n",
    "                                         self.bt_len] = np.arange(1, self.bt_len + 1)\n",
    "\n",
    "    def cleanup(self):\n",
    "        for p in self.histowner:\n",
    "            p.Delete()\n",
    "        self.histowner.clear()\n",
    "\n",
    "    def gather_results(self, datacollection):\n",
    "        \"\"\" Write here how to build the datacollection and its NNdata\n",
    "        \"\"\"\n",
    "        print(\"nnDumper::Enter gather_results\")\n",
    "\n",
    "        print(\"Collect general objects:\")\n",
    "\n",
    "        # create np array containing the gap to previous signal\n",
    "        self.get_gap_to_previous()\n",
    "        self.get_gap_to_previous_for_all_bcs()\n",
    "\n",
    "        # assign the bunchtrain for each BC\n",
    "        self.get_bunchtrain()\n",
    "\n",
    "        print(\"nnDumper::Exit gather_results\")\n",
    "        return True\n",
    "\n",
    "    def add_prediction(self, name, preds):\n",
    "        pred = [-14000.0 for i in range(len(self.adc))]\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            pred[i + self.start] = preds[i]\n",
    "\n",
    "        self.preds[name] = np.array(pred)\n",
    "\n",
    "    def dump_results(self):\n",
    "        print(\"nnDumper::Enter dump_results\")\n",
    "\n",
    "        outName = self.name  # \"prediction_output_store\"\n",
    "\n",
    "        print(\"nnDumper::Make TTree\")\n",
    "        with uproot.recreate(outName + \".root\") as outfile:\n",
    "            \"\"\"\n",
    "            treedict = {\"sequence_dig_eT\": \"float32\",\n",
    "                        \"sequence_hit_eT\": \"float32\",\n",
    "                        \"sequence_sig_eT\": \"float32\",\n",
    "                        \"sequence_ofmax_eT\": \"float32\",\n",
    "                        \"sequence_gap_to_signal\": \"float32\",\n",
    "                        \"sequence_gap_to_signal_for_all_bcs\": \"float32\",\n",
    "                        \"sequence_bunchtrain\": \"float32\"}\n",
    "\n",
    "            for Id in self.preds.keys():\n",
    "                treedict[Id] = \"float32\"\n",
    "\n",
    "            outfile[\"Events\"] = uproot.newtree(treedict)\n",
    "            \"\"\"\n",
    "            datadict = {\"sequence_dig_eT\": self.adc.astype(\"float32\"),\n",
    "                        \"sequence_hit_eT\": self.edepo.astype(\"float32\"),\n",
    "                        \"sequence_sig_eT\": self.sig.astype(\"float32\"),\n",
    "                        \"sequence_gap_to_signal\": self.gap.astype(\"float32\"),\n",
    "                        \"sequence_ofmax_eT\": self.ofmax.astype(\"float32\"),\n",
    "                        \"sequence_gap_to_signal_for_all_bcs\": self.gap_for_all_bcs.astype(\"float32\"),\n",
    "                        \"sequence_bunchtrain\": self.bunchtrain_position.astype(\"float32\")}\n",
    "\n",
    "            for Id in self.preds.keys():\n",
    "                datadict[Id] = self.preds[Id].astype(\"float32\")\n",
    "\n",
    "            outfile[\"Events\"] = datadict\n",
    "\n",
    "        print(\"nnDumper::Done with tree, skipping THs\")\n",
    "        \"\"\"\n",
    "        nbins = len(self.bcid)\n",
    "        xi = self.bcid[0]\n",
    "        xf = self.bcid[-1]\n",
    "\n",
    "        rf = ROOT.TFile(outName + \".root\", 'update')\n",
    "\n",
    "        hadc = ROOT.TH1F(\"sequence_dig_eT\", \"sequence_dig_eT\", nbins, xi, xf)\n",
    "        hadc.SetDirectory(0)\n",
    "        hedepo = ROOT.TH1F(\"sequence_hit_eT\", \"sequence_hit_eT\", nbins, xi, xf)\n",
    "        hedepo.SetDirectory(0)\n",
    "        hsig = ROOT.TH1F(\"sequence_sig_eT\", \"sequence_sig_eT\", nbins, xi, xf)\n",
    "        hsig.SetDirectory(0)\n",
    "\n",
    "        hgap = ROOT.TH1F(\"sequence_gap_to_signal\",\n",
    "                         \"sequence_gap_to_signal\", nbins, xi, xf)\n",
    "        hgap.SetDirectory(0)\n",
    "        hgap_for_all = ROOT.TH1F(\"sequence_gap_to_signal_for_all_bcs\",\n",
    "                                 \"sequence_gap_to_signal_for_all_bcs\", nbins, xi, xf)\n",
    "        hgap_for_all.SetDirectory(0)\n",
    "\n",
    "        hseq_bt = ROOT.TH1F(\"sequence_bunchtrain\",\n",
    "                            \"sequence_bunchtrain\", nbins, xi, xf)\n",
    "        hseq_bt.SetDirectory(0)\n",
    "\n",
    "        hofmax = ROOT.TH1F(\"sequence_ofmax_eT\",\n",
    "                           \"sequence_ofmax_eT\", nbins, xi, xf)\n",
    "        hofmax.SetDirectory(0)\n",
    "\n",
    "        for ib, adc in enumerate(self.adc):\n",
    "            hadc.SetBinContent(ib + 1, adc)\n",
    "            hedepo.SetBinContent(ib + 1, self.edepo[ib])\n",
    "            hsig.SetBinContent(ib + 1, self.sig[ib])\n",
    "            hgap.SetBinContent(ib + 1, self.gap[ib])\n",
    "            hgap_for_all.SetBinContent(ib + 1, self.gap_for_all_bcs[ib])\n",
    "            hofmax.SetBinContent(ib + 1, self.ofmax[ib])\n",
    "            hseq_bt.SetBinContent(ib + 1, self.bunchtrain_position[ib])\n",
    "        release(hadc, self.histowner)\n",
    "        release(hedepo, self.histowner)\n",
    "        release(hsig, self.histowner)\n",
    "        release(hgap, self.histowner)\n",
    "        release(hgap_for_all, self.histowner)\n",
    "        release(hofmax, self.histowner)\n",
    "        release(hseq_bt, self.histowner)\n",
    "\n",
    "        hadc.Write()\n",
    "        hedepo.Write()\n",
    "        hsig.Write()\n",
    "        hgap.Write()\n",
    "        hgap_for_all.Write()\n",
    "        hofmax.Write()\n",
    "        hseq_bt.Write()\n",
    "\n",
    "        for Id in self.preds.keys():\n",
    "            hpred = ROOT.TH1F(\"sequence_\" + Id + \"_eT\",\n",
    "                              \"sequence_\" + Id + \"_eT\", nbins, xi, xf)\n",
    "            hpred.SetDirectory(0)\n",
    "            for ib, pred in enumerate(self.preds[Id]):\n",
    "                hpred.SetBinContent(ib + 1, pred)\n",
    "                release(hpred, self.histowner)\n",
    "            hpred.Write()\n",
    "\n",
    "        rf.Close()\n",
    "        \"\"\"\n",
    "        print(\"nnDumper::Exit dump_results\")\n",
    "\n",
    "    def runme(self, datacollection=None):\n",
    "\n",
    "        self.gather_results(self.rootData)\n",
    "\n",
    "        self.dump_results()\n",
    "\n",
    "        self.cleanup()\n",
    "\n",
    "\n",
    "#pointers_in_the_wild = set()\n",
    "\n",
    "def release(obj, container=None):\n",
    "    \"\"\" Tell python that no, we don't want to lose this one when current function returns \"\"\"\n",
    "    global pointers_in_the_wild\n",
    "    if container is None:\n",
    "        pointers_in_the_wild.add(obj)\n",
    "    else:\n",
    "        container.add(obj)\n",
    "    ROOT.SetOwnership(obj, False)\n",
    "    return obj\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "978a78fee93b9f75d300423e922c5a4da2d32993b15c09db9f940a22d4b78528"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('hls4ml-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
