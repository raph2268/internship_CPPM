{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QKeras RNN comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a model and compare its performance to the boosted model\n",
    "2. If the model outreach the performance of the boosted model : \n",
    " -   create a model with the same feature with qkeras (QAT) and \n",
    " -   quantized the keras model (PTQ)\n",
    "3. Compare those two to PTQ boosted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models with keras should converge to around 1e-5 or 9.8e-6\n",
    "\n",
    "For QKeras it's been somewhere around 1.1e-5 or so\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Run Everytime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/hls4ml-0.5.1-py3.7.egg/hls4ml/converters/__init__.py:15: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, LSTM, GRU, SimpleRNN, Conv2D, MaxPooling2D, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "from collections import deque\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "\n",
    "import hls4ml\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries if they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (1999995, 5, 1) (1999995, 1)\n",
      "shapes (899992, 5, 1) (99995, 5, 1) (999998, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "from nnlar.datashaper import DataShaper\n",
    "ds = DataShaper.from_h5(\"../../../data/rdgap_mu140.h5\")\n",
    "\n",
    "x, x_val, x_test, y, y_val, y_test = ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 13:25:17.195038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-22 13:25:17.195057: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-22 13:25:17.195069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marsattack3): /proc/driver/nvidia/version does not exist\n",
      "2022-07-22 13:25:17.195229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 8)                 80        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "boosted_model =  tf.keras.models.load_model('/atlas/bonnet/Desktop/code/internship_CPPM/pb_file')\n",
    "\n",
    "boosted_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings of the networks \n",
    "output = 1\n",
    "\n",
    "nbr_batch = 128\n",
    "nbr_epoch = 200\n",
    "lr=0.001\n",
    "\n",
    "nbr_conv_epoch = 4 #number of epochs for the conversion \n",
    "\n",
    "patience_es = 8\n",
    "patience_rlr = 5\n",
    "delta = 0.0000001\n",
    "\n",
    "def version(v): return (v)\n",
    "versions_range = 8\n",
    "\n",
    "def units(j): return (j+8)\n",
    "units_range = 1\n",
    "j=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "\n",
    "#path of the tested models \n",
    "def models_path32(j,v) : return f\"tests/models/models_units={units(j)}_batchsize=32v{version(v)}.h5\"\n",
    "#path of the tested models \n",
    "def predicts_path32(j,v) : return f\"tests/predicts/models_units={units(j)}_batchsize=32v{version(v)}.npy\"\n",
    "\n",
    "#path of the tested models \n",
    "def models_path64(j,v) : return f\"tests/models/models_units={units(j)}_batchsize=64v{version(v)}.h5\"\n",
    "#path of the tested models \n",
    "def predicts_path64(j,v) : return f\"tests/predicts/models_units={units(j)}_batchsize=64v{version(v)}.npy\"\n",
    "\n",
    "#path of the tested models \n",
    "def models_path128(j,v) : return f\"tests/models/models_units={units(j)}_batchsize=128v{version(v)}.h5\"\n",
    "#path of the tested models \n",
    "def predicts_path128(j,v) : return f\"tests/predicts/models_units={units(j)}_batchsize=128v{version(v)}.npy\"\n",
    "\n",
    "#path of the tested models \n",
    "def models_path256(j,v) : return f\"tests/models/models_units={units(j)}_batchsize=256v{version(v)}.h5\"\n",
    "#path of the tested models \n",
    "def predicts_path256(j,v) : return f\"tests/predicts/models_units={units(j)}_batchsize=256v{version(v)}.npy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist(path,modeltopred):\n",
    "    if (os.path.exists(path)==False):\n",
    "        np.save(path, modeltopred.predict(x_test))\n",
    "     \n",
    "    else : print(f'{path} already exists')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests/ref_predicts.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v0.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v0.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v0.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v0.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v1.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v1.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v1.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v1.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v2.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v2.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v2.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v2.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v3.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v3.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v3.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v3.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v4.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v4.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v4.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v4.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v5.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v5.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v5.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v5.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v6.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v6.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v6.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v6.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=32v7.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=64v7.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=128v7.npy already exists\n",
      "tests/predicts/models_units=8_batchsize=256v7.npy already exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref = 'tests/ref_predicts.npy'\n",
    "exist(ref, boosted_model)\n",
    "\n",
    "\n",
    "for v in range (versions_range):\n",
    "        \n",
    "    exist(predicts_path32(j,v),tf.keras.models.load_model(models_path32(j,v)))\n",
    "    exist(predicts_path64(j,v),tf.keras.models.load_model(models_path64(j,v)))\n",
    "    exist(predicts_path128(j,v),tf.keras.models.load_model(models_path128(j,v)))\n",
    "    exist(predicts_path256(j,v),tf.keras.models.load_model(models_path256(j,v)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=[]\n",
    "bits=[]\n",
    "mean=[]\n",
    "\n",
    "error=[]\n",
    "loss=[]\n",
    "x.append(0)\n",
    "bits.append(32)\n",
    "best_mse=100\n",
    "worst_mse=00\n",
    "tmp_loss=[]\n",
    "sum = 0\n",
    "for v in range (versions_range):\n",
    "    y_keras0 = np.load(predicts_path64(j,v))\n",
    "    tmp_mse = mse(y_test,y_keras0)\n",
    "    sum = sum+tmp_mse\n",
    "    tmp_loss.append(tmp_mse)\n",
    "\n",
    "loss.append(sum/versions_range)\n",
    "mean.append(sum/versions_range)\n",
    "error.append(np.std(tmp_loss))\n",
    "plt.errorbar(x=x,y=loss, yerr=error)\n",
    "\n",
    "x=[]\n",
    "error=[]\n",
    "loss=[]\n",
    "x.append(1)\n",
    "bits.append(64)\n",
    "best_mse=100\n",
    "worst_mse=00\n",
    "tmp_loss=[]\n",
    "sum = 0\n",
    "for v in range (versions_range):\n",
    "    y_keras0 = np.load(predicts_path64(j,v))\n",
    "    tmp_mse = mse(y_test,y_keras0)\n",
    "    sum = sum+tmp_mse\n",
    "\n",
    "    tmp_loss.append(tmp_mse)\n",
    "    if (best_mse>tmp_mse): best_mse=tmp_mse\n",
    "    if (worst_mse<tmp_mse): worst_mse=tmp_mse      \n",
    "loss.append(sum/versions_range)\n",
    "mean.append(sum/versions_range)\n",
    "error.append(np.std(tmp_loss))\n",
    "plt.errorbar(x=x,y=loss, yerr=error)\n",
    "\n",
    "x=[]\n",
    "error=[]\n",
    "loss=[]\n",
    "x.append(2)\n",
    "bits.append(128)\n",
    "best_mse=100\n",
    "worst_mse=00\n",
    "tmp_loss=[]\n",
    "sum = 0\n",
    "for v in range (versions_range):\n",
    "    y_keras0 = np.load(predicts_path128(j,v))\n",
    "    tmp_mse = mse(y_test,y_keras0)\n",
    "    sum = sum+tmp_mse\n",
    "\n",
    "    tmp_loss.append(tmp_mse)\n",
    "    if (best_mse>tmp_mse): best_mse=tmp_mse\n",
    "    if (worst_mse<tmp_mse): worst_mse=tmp_mse      \n",
    "loss.append(sum/versions_range)\n",
    "mean.append(sum/versions_range)\n",
    "error.append(np.std(tmp_loss))\n",
    "plt.errorbar(x=x,y=loss, yerr=error)\n",
    "\n",
    "\n",
    "x=[]\n",
    "error=[]\n",
    "loss=[]\n",
    "x.append(3)\n",
    "bits.append(256)\n",
    "best_mse=100\n",
    "worst_mse=00\n",
    "tmp_loss=[]\n",
    "sum = 0\n",
    "for v in range (versions_range):\n",
    "    y_keras0 = np.load(predicts_path256(j,v))\n",
    "    tmp_mse = mse(y_test,y_keras0)\n",
    "    sum = sum+tmp_mse\n",
    "\n",
    "    tmp_loss.append(tmp_mse)\n",
    "    if (best_mse>tmp_mse): best_mse=tmp_mse\n",
    "    if (worst_mse<tmp_mse): worst_mse=tmp_mse      \n",
    "loss.append(sum/versions_range)\n",
    "mean.append(sum/versions_range)\n",
    "error.append(np.std(tmp_loss))\n",
    "\n",
    "plt.errorbar(x=x,y=loss, yerr=error)\n",
    "\n",
    "plt.axhline(mse(y_test, np.load(ref)), linestyle=\"--\", color = 'red')\n",
    "plt.plot(mean, 'r+')\n",
    "plt.legend(['ref','mean'])\n",
    "plt.title(f'MSEs of keras models, comparison with different batch size')\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Batch size\")   \n",
    "plt.xticks(np.arange(len(bits)), [f\"{Bit}\" for Bit in bits])\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "978a78fee93b9f75d300423e922c5a4da2d32993b15c09db9f940a22d4b78528"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('hls4ml-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
