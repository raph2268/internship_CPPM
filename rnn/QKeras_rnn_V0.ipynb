{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QKeras RNN comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 13:49:03.412876: I tensorflow/core/util/util.cc:168] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-06 13:49:03.418833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-06 13:49:03.418848: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name convert optimizers ['fuse_bias_add', 'remove_useless_transpose', 'output_rounding_saturation_mode', 'qkeras_factorize_alpha', 'extract_ternary_threshold', 'fuse_consecutive_batch_normalization'] File: flow.py Line: 23\n",
      "name optimize optimizers ['eliminate_linear_activation', 'fuse_consecutive_batch_normalization', 'fuse_batch_normalization', 'replace_multidimensional_dense_with_conv'] File: flow.py Line: 23\n",
      "vivado:merge_batch_norm_quantized_tanh Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:quantize_dense_output Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalizationquantizedtanh_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalizationquantizedtanh_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:clone_output Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:clone_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:optimize_pointwise_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:remove_final_reshape Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:reshape_stream Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_stream Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:repack_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_depconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_depconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet_stack Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet_stack Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:register_bram_weights Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:insert_zero_padding_before_conv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:insert_zero_padding_before_conv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:generate_conv_streaming_instructions Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv2d_conv2dbatchnorm_depthwiseconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv2d_conv2dbatchnorm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:depthwiseconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnet_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnet_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnetstack_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnetstack_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:merge_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:merge_concatenate_dot_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dot_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:concatenate_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:applyalpha_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:applyalpha_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:zeropadding1d_zeropadding2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:zeropadding1d_zeropadding2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:resize_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:resize_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transpose_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transpose_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:apply_resource_strategy Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "name init_layers optimizers ['vivado:init_base_layer', 'vivado:init_activation', 'vivado:init_conv1d', 'vivado:init_conv2d', 'vivado:init_dense', 'vivado:init_garnet', 'vivado:init_sepconv1d', 'vivado:init_sepconv2d', 'vivado:init_depconv2d', 'vivado:init_garnet_stack', 'vivado:init_softmax'] File: flow.py Line: 23\n",
      "name streaming optimizers ['vivado:remove_final_reshape', 'vivado:reshape_stream', 'vivado:clone_output', 'vivado:insert_zero_padding_before_conv1d', 'vivado:insert_zero_padding_before_conv2d', 'vivado:broadcast_stream'] File: flow.py Line: 23\n",
      "name quantization optimizers ['vivado:merge_batch_norm_quantized_tanh', 'vivado:quantize_dense_output', 'fuse_consecutive_batch_normalization'] File: flow.py Line: 23\n",
      "name optimize optimizers ['vivado:optimize_pointwise_conv'] File: flow.py Line: 23\n",
      "name specific_types optimizers ['vivado:register_bram_weights', 'vivado:transform_types', 'vivado:generate_conv_streaming_instructions', 'vivado:apply_resource_strategy'] File: flow.py Line: 23\n",
      "vivado:merge_batch_norm_quantized_tanh Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:quantize_dense_output Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalizationquantizedtanh_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalizationquantizedtanh_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:clone_output Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:clone_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:optimize_pointwise_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pointwiseconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:remove_final_reshape Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:reshape_stream Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_stream Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:repack_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:broadcast_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_conv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_depconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_garnet_stack Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_sepconv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:register_bram_weights Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:insert_zero_padding_before_conv1d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:insert_zero_padding_before_conv2d Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:generate_conv_streaming_instructions Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv2d_conv2dbatchnorm_depthwiseconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:conv2d_conv2dbatchnorm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:depthwiseconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv1d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv1d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:separableconv2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnet_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnet_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnetstack_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:garnetstack_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:merge_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:merge_concatenate_dot_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:dot_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:concatenate_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:applyalpha_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:applyalpha_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:zeropadding1d_zeropadding2d_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:zeropadding1d_zeropadding2d_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:resize_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:resize_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transpose_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transpose_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:apply_resource_strategy Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "vivado:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "name apply_templates optimizers ['vivado:batchnormalizationquantizedtanh_config_template', 'vivado:batchnormalizationquantizedtanh_function_template', 'vivado:clone_function_template', 'vivado:pointwiseconv1d_config_template', 'vivado:pointwiseconv1d_function_template', 'vivado:pointwiseconv2d_config_template', 'vivado:pointwiseconv2d_function_template', 'vivado:repack_function_template', 'vivado:broadcast_config_template', 'vivado:broadcast_function_template', 'vivado:conv1d_config_template', 'vivado:conv1d_function_template', 'vivado:conv2d_conv2dbatchnorm_depthwiseconv2d_config_template', 'vivado:conv2d_conv2dbatchnorm_function_template', 'vivado:depthwiseconv2d_function_template', 'vivado:separableconv1d_config_template', 'vivado:separableconv1d_function_template', 'vivado:separableconv2d_config_template', 'vivado:separableconv2d_function_template', 'vivado:dense_config_template', 'vivado:dense_function_template', 'vivado:batchnormalization_config_template', 'vivado:batchnormalization_function_template', 'vivado:activation_parametrizedactivation_prelu_config_template', 'vivado:softmax_config_template', 'vivado:activation_softmax_function_template', 'vivado:parametrizedactivation_function_template', 'vivado:prelu_function_template', 'vivado:garnet_config_template', 'vivado:garnet_function_template', 'vivado:garnetstack_config_template', 'vivado:garnetstack_function_template', 'vivado:merge_config_template', 'vivado:merge_concatenate_dot_function_template', 'vivado:dot_config_template', 'vivado:concatenate_config_template', 'vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_config_template', 'vivado:pooling1d_pooling2d_globalpooling1d_globalpooling2d_function_template', 'vivado:applyalpha_config_template', 'vivado:applyalpha_function_template', 'vivado:zeropadding1d_zeropadding2d_config_template', 'vivado:zeropadding1d_zeropadding2d_function_template', 'vivado:resize_config_template', 'vivado:resize_function_template', 'vivado:transpose_config_template', 'vivado:transpose_function_template'] File: flow.py Line: 23\n",
      "name write optimizers ['vivado:write_hls'] File: flow.py Line: 23\n",
      "name ip optimizers None File: flow.py Line: 23\n",
      "name write optimizers ['vivadoaccelerator:write_hls'] File: flow.py Line: 23\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "name init_layers optimizers ['quartus:init_base_layer', 'quartus:init_activation', 'quartus:init_dense', 'quartus:init_softmax'] File: flow.py Line: 23\n",
      "name specific_types optimizers ['quartus:transform_types'] File: flow.py Line: 23\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "name apply_templates optimizers ['quartus:lstm_config_template', 'quartus:lstm_function_template', 'quartus:simplernn_config_template', 'quartus:simplernn_function_template', 'quartus:dense_config_template', 'quartus:dense_function_template', 'quartus:batchnormalization_config_template', 'quartus:batchnormalization_function_template', 'quartus:activation_parametrizedactivation_prelu_config_template', 'quartus:softmax_config_template', 'quartus:activation_softmax_function_template', 'quartus:parametrizedactivation_function_template', 'quartus:prelu_function_template'] File: flow.py Line: 23\n",
      "name write optimizers ['quartus:write_hls'] File: flow.py Line: 23\n",
      "name ip optimizers None File: flow.py Line: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/bonnet/hls4ml/hls4ml/hls4ml/hls4ml/converters/__init__.py:15: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, LSTM, GRU, SimpleRNN, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "\n",
    "import hls4ml\n",
    "import nnlar\n",
    "from nnlar.datashaper import DataShaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries if they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (1999995, 5, 1) (1999995, 1)\n",
      "shapes (899992, 5, 1) (99995, 5, 1) (999998, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "from nnlar.datashaper import DataShaper\n",
    "ds = DataShaper.from_h5(\"../data/rdgap_mu140.h5\")\n",
    "\n",
    "x, x_val, x_test, y, y_val, y_test = ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 1\n",
    "integer = (3)\n",
    "\n",
    "def bit_lenghts(i):\n",
    "    #To change to create models with different bits parameter by defining the smallest bit lenghts \n",
    "    #Example : bits 8 ==> (i+4)*4\n",
    "    return (i+6)\n",
    "\n",
    "def bit_width(i): return {'bits': (i+6), 'integer': integer, 'symmetric': 0, 'alpha':1}\n",
    "\n",
    "bits_range = 3\n",
    "\n",
    "nbr_epoch = 15\n",
    "\n",
    "def units(j): return (j+3)*3\n",
    "units_range = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " SimpleRNN (SimpleRNN)       (None, 8)                 80        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 13:49:28.460737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-06 13:49:28.460766: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-06 13:49:28.460787: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (martop): /proc/driver/nvidia/version does not exist\n",
      "2022-05-06 13:49:28.461148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                patience=10, \n",
    "                                                restore_best_weights=True, \n",
    "                                                min_delta=0.000001,\n",
    "                                                mode='min')\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                            patience=5, min_lr=0.000001, verbose=1)\n",
    "\n",
    "r_model = Sequential()\n",
    "r_model.add(SimpleRNN(8, input_shape=(5, 1), return_sequences=False, name='SimpleRNN'))\n",
    "r_model.add(Dense(output, activation='relu',name='dense'))\n",
    "r_model.compile(loss=\"mean_squared_error\", optimizer=Adam(lr=0.001))\n",
    "\n",
    "\n",
    "r_model.summary()\n",
    "\n",
    "#r_model.fit(x,y,validation_data=(x_val,y_val), epochs=1, batch_size=20, shuffle=True, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7130/239724627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mqmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mqmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqmodel_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7130/239724627.py\u001b[0m in \u001b[0;36mqmodel_saving\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mbits_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbit_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0munits_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mvar_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mquantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbits_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mqmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'bit width '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbits_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "def quantized_model (bits, units, original_weights):  \n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                    patience=10, \n",
    "                                                    restore_best_weights=True, \n",
    "                                                    min_delta=0.000001,\n",
    "                                                    mode='min')\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                patience=5, min_lr=0.000001, verbose=1)  \n",
    "    qr_model = Sequential()\n",
    "    \n",
    "    qr_model.add(QSimpleRNN(units,\n",
    "                        input_dim= 1,\n",
    "                        activation='relu',   \n",
    "                        kernel_quantizer=quantized_bits(**bits),\n",
    "                        bias_quantizer=quantized_bits(**bits)))\n",
    "       \n",
    "    #qr_model.add(QActivation(activation=quantized_relu(bits=bits['bits'], integer = bits['integer']), name='relu1'))                   \n",
    "    qr_model.add(QDense(output, \n",
    "                        activation='linear',\n",
    "                        kernel_quantizer=quantized_bits(**bits),\n",
    "                        bias_quantizer=quantized_bits(**bits)))\n",
    "    #qr_model.add(QActivation(activation=quantized_bits(**bits), name='linear1'))\n",
    "    qr_model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "    \n",
    "    qr_model.summary()\n",
    "    \n",
    "    #using the weight from the classic network as a base\n",
    "    qr_model.set_weights(original_weights.get_weights())\n",
    "    qr_model.fit(x, y, validation_data= (x_val,y_val),epochs = nbr_epoch, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    return qr_model\n",
    "\n",
    "def qmodel_saving (): \n",
    "    qmodels =[]\n",
    "    for i in range(bits_range):\n",
    "        var_units= []\n",
    "        for j in range(units_range):\n",
    "            bits_parameter = bit_width(i)\n",
    "            units_parameter = units(j)\n",
    "            var_units.append( quantized_model(bits_parameter,units_parameter, models[j]))\n",
    "        qmodels.append(var_units)\n",
    "        print( 'bit width ', bits_parameter)        \n",
    "    return qmodels\n",
    "        \n",
    "qmodels = qmodel_saving()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS CONVERSION of the keras model, every layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: SimpleRNN_input, layer type: Input\n",
      "Layer name: SimpleRNN, layer type: SimpleRNN\n",
      "  -> Activation (tanh), layer name: SimpleRNN\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'SimpleRNN_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, 'SimpleRNN': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>'}}, 'SimpleRNN_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, 'dense': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}}}\n",
      "['Conv1D', 'SeparableConv1D', 'Conv2D', 'SeparableConv2D', 'DepthwiseConv2D', 'InputLayer', 'Dense', 'BinaryDense', 'TernaryDense', 'Activation', 'LeakyReLU', 'ThresholdedReLU', 'ELU', 'PReLU', 'Softmax', 'ReLU', 'LSTM', 'SimpleRNN', 'BatchNormalization', 'GarNet', 'GarNetStack', 'Add', 'Subtract', 'Multiply', 'Average', 'Maximum', 'Minimum', 'Concatenate', 'Dot', 'MaxPooling1D', 'MaxPooling2D', 'AveragePooling1D', 'AveragePooling2D', 'GlobalMaxPooling1D', 'GlobalMaxPooling2D', 'GlobalAveragePooling1D', 'GlobalAveragePooling2D', 'QDense', 'QConv1D', 'QConv2D', 'QActivation', 'QBatchNormalization', 'QConv2DBatchnorm', 'Flatten', 'Reshape', 'UpSampling2D', 'Permute', 'ZeroPadding1D', 'ZeroPadding2D'] Layer list File:converters/keras_to_hls.py Ligne: 98\n",
      "Interpreting Sequential\n",
      "InputLayer Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "SimpleRNN Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "Dense Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "Topology:\n",
      "Layer name: SimpleRNN_input, layer type: InputLayer, input shapes: [[None, 5, 1]], output shape: [None, 5, 1]\n",
      "{'class_name': 'SimpleRNN', 'config': {'name': 'SimpleRNN', 'trainable': True, 'batch_input_shape': [None, 5, 1], 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 8, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0}}\n",
      "[[None, 5, 1]]\n",
      "Layer name: SimpleRNN, layer type: SimpleRNN, input shapes: [[None, 5, 1]], output shape: [None, 5, 8]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 5, 8]], output shape: [None, 5, 1]\n",
      "Creating HLS model\n",
      "Model HLSModel\n",
      "config {'OutputDir': 'models/hls_models', 'ProjectName': 'myproject', 'Backend': 'Quartus', 'Part': '1SG280HU2F50E2VG', 'ClockPeriod': 5, 'IOType': 'io_parallel', 'HLSConfig': {'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'SimpleRNN_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, 'SimpleRNN': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>'}}, 'SimpleRNN_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, 'dense': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}}}, 'KerasModel': <keras.engine.sequential.Sequential object at 0x7f75f21bb190>, 'InputData': None, 'OutputPredictions': None}\n",
      "name\n",
      "self.flows ['quartus:ip'] File:hls_model.py Line: 180\n",
      "2 SELF_index, hls_layer, linha 997\n",
      "flows from __init__ quartus:ip File: hls_model.py Line: 324\n",
      "apply_flow quartus:ip File: hls_model.py Line 354\n",
      "flow_name quartus:ip File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344310> flow_map\n",
      "flow_optimizers [] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name optimize File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f214c550> flow_map\n",
      "flow_optimizers ['eliminate_linear_activation', 'fuse_consecutive_batch_normalization', 'fuse_batch_normalization', 'replace_multidimensional_dense_with_conv'] File: hls_model.py Line 366\n",
      "Flow requires: ['convert'] File:hls_model.py Line: 368\n",
      "flow_name convert File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f214c310> flow_map\n",
      "flow_optimizers ['fuse_bias_add', 'remove_useless_transpose', 'output_rounding_saturation_mode', 'qkeras_factorize_alpha', 'extract_ternary_threshold', 'fuse_consecutive_batch_normalization'] File: hls_model.py Line 366\n",
      "fuse_bias_add Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "remove_useless_transpose Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "output_rounding_saturation_mode Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "qkeras_factorize_alpha Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "extract_ternary_threshold Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "eliminate_linear_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "replace_multidimensional_dense_with_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:init_layers File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344150> flow_map\n",
      "flow_optimizers ['quartus:init_base_layer', 'quartus:init_activation', 'quartus:init_dense', 'quartus:init_softmax'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize'] File:hls_model.py Line: 368\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:specific_types File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_base_layer', 'quartus:init_dense', 'quartus:init_activation'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344110> flow_map\n",
      "flow_optimizers ['quartus:transform_types'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:apply_templates File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_base_layer', 'quartus:init_dense', 'quartus:init_activation'}, 'quartus:specific_types': {'quartus:transform_types'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344190> flow_map\n",
      "flow_optimizers ['quartus:lstm_config_template', 'quartus:lstm_function_template', 'quartus:simplernn_config_template', 'quartus:simplernn_function_template', 'quartus:dense_config_template', 'quartus:dense_function_template', 'quartus:batchnormalization_config_template', 'quartus:batchnormalization_function_template', 'quartus:activation_parametrizedactivation_prelu_config_template', 'quartus:softmax_config_template', 'quartus:activation_softmax_function_template', 'quartus:parametrizedactivation_function_template', 'quartus:prelu_function_template'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "none olha aqui\n",
      "apply_flow quartus:write File: hls_model.py Line 354\n",
      "flow_name quartus:write File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344210> flow_map\n",
      "flow_optimizers ['quartus:write_hls'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name optimize File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f214c550> flow_map\n",
      "flow_optimizers ['eliminate_linear_activation', 'fuse_consecutive_batch_normalization', 'fuse_batch_normalization', 'replace_multidimensional_dense_with_conv'] File: hls_model.py Line 366\n",
      "Flow requires: ['convert'] File:hls_model.py Line: 368\n",
      "flow_name convert File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f214c310> flow_map\n",
      "flow_optimizers ['fuse_bias_add', 'remove_useless_transpose', 'output_rounding_saturation_mode', 'qkeras_factorize_alpha', 'extract_ternary_threshold', 'fuse_consecutive_batch_normalization'] File: hls_model.py Line 366\n",
      "fuse_bias_add Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "remove_useless_transpose Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "output_rounding_saturation_mode Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "qkeras_factorize_alpha Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "extract_ternary_threshold Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "eliminate_linear_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "replace_multidimensional_dense_with_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:specific_types File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344110> flow_map\n",
      "flow_optimizers ['quartus:transform_types'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "flow_name quartus:init_layers File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344150> flow_map\n",
      "flow_optimizers ['quartus:init_base_layer', 'quartus:init_activation', 'quartus:init_dense', 'quartus:init_softmax'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize'] File:hls_model.py Line: 368\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:apply_templates File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_base_layer', 'quartus:init_dense', 'quartus:init_activation'}, 'quartus:specific_types': {'quartus:transform_types'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f75f1344190> flow_map\n",
      "flow_optimizers ['quartus:lstm_config_template', 'quartus:lstm_function_template', 'quartus:simplernn_config_template', 'quartus:simplernn_function_template', 'quartus:dense_config_template', 'quartus:dense_function_template', 'quartus:batchnormalization_config_template', 'quartus:batchnormalization_function_template', 'quartus:activation_parametrizedactivation_prelu_config_template', 'quartus:softmax_config_template', 'quartus:activation_softmax_function_template', 'quartus:parametrizedactivation_function_template', 'quartus:prelu_function_template'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "none olha aqui\n",
      "quartus:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Writing HLS project\n",
      "layer2_t layer2_out[OUT_HEIGHT_2] def_cpp quartus writer linha 131\n",
      "layer3_t layer3_out[N_LAYER_3] def_cpp quartus writer linha 131\n",
      "Quartus_writer.py ligne 998\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from firmware/parameters.h:11:0,\n",
      "                 from firmware/myproject.h:33,\n",
      "                 from firmware/myproject.cpp:21:\n",
      "firmware/nnet_utils/simple_rnn_cell.h:2:21: fatal error: HLS/hls.h: No such file or directory\n",
      " #include \"HLS/hls.h\"\n",
      "                     ^\n",
      "compilation terminated.\n",
      "In file included from firmware/parameters.h:11:0,\n",
      "                 from firmware/myproject.h:33,\n",
      "                 from myproject_bridge.cpp:4:\n",
      "firmware/nnet_utils/simple_rnn_cell.h:2:21: fatal error: HLS/hls.h: No such file or directory\n",
      " #include \"HLS/hls.h\"\n",
      "                     ^\n",
      "compilation terminated.\n",
      "g++: error: myproject.o: No such file or directory\n",
      "g++: error: myproject_bridge.o: No such file or directory\n",
      "g++: fatal error: no input files\n",
      "compilation terminated.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "models/hls_models/firmware/myproject-8aD0f7cC.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_146767/105374676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                             \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1SG280HU2F50E2VG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                             backend='Quartus')\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#y_qckeras = tmp_models[i].predict(x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hls4ml/hls4ml/hls4ml/hls4ml/model/graph.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_top_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: models/hls_models/firmware/myproject-8aD0f7cC.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "closs = []\n",
    "qcloss = []\n",
    "qchloss = []\n",
    "ptq_results = []\n",
    "\n",
    "bit_scale = []\n",
    "for i in range (bits_range):\n",
    "    conf = hls4ml.utils.config_from_keras_model( r_model, granularity='name')\n",
    "    conf['LayerName']['dense']['Precision']['weight'] = f'ap_fixed<{bit_lenghts(i)},{integer+1}>'\n",
    "    conf['LayerName']['dense']['Precision']['bias'] = f'ap_fixed<{bit_lenghts(i)},{integer+1}>'\n",
    "    conf['LayerName']['SimpleRNN']['Precision'] ={'weight' : f'ap_fixed<{bit_lenghts(i)},{integer+1}>', 'bias': f'ap_fixed<{bit_lenghts(i)},{integer+1}>' }\n",
    "\n",
    "    \n",
    "    print(conf)\n",
    "        \n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(r_model,\n",
    "                                                            hls_config=conf,\n",
    "                                                            output_dir='models/hls_models',\n",
    "                                                            part='1SG280HU2F50E2VG',\n",
    "                                                            backend='Quartus')\n",
    "    hls_model.compile()\n",
    "\n",
    "    #y_qckeras = tmp_models[i].predict(x_test)\n",
    "    y_qchls = hls_model.predict(x_test.reshape(x_test.shape[0],1))\n",
    "    ptq_results.append(y_qchls)\n",
    "    y_keras = r_model.predict(x_test)\n",
    "    closs.append(mse(y_test, y_keras))\n",
    "    #qcloss.append(mse(y_test, y_qckeras))\n",
    "    qchloss.append(mse(y_test, y_qchls))\n",
    "    bit_scale.append(bit_lenghts(i))\n",
    "    plt.figure()\n",
    "    #plt.plot(y_qckeras, '--', linewidth=2)\n",
    "    plt.plot(y_qchls)\n",
    "    plt.plot(y_test)    \n",
    "    plt.legend(['keras+hls', 'keras'])\n",
    "    plt.title(f'PTQ : bitwidths of ({bit_lenghts(i)},{integer},0,1)')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bit_scale, qchloss)\n",
    "plt.xlabel('bits')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'PTQ : bitwidths of (x,{integer},0,1), {nbr_epoch} epochs')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, \n",
    "'LayerName': {'simple_rnn_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, \n",
    "            'simple_rnn': {'Precision': 'ap_fixed<16,6>'}, \n",
    "            'simple_rnn_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, \n",
    "            'dense': {'Precision': {'weight': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, \n",
    "            'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS CONVERSION of the QKeras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "978a78fee93b9f75d300423e922c5a4da2d32993b15c09db9f940a22d4b78528"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('hls4ml-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
