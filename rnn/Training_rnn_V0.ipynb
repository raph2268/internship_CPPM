{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QKeras RNN comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Run Everytime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10698/514695483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gfile'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import gfile \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, LSTM, GRU, SimpleRNN, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import qkeras\n",
    "from qkeras import *\n",
    "\n",
    "import hls4ml\n",
    "import nnlar\n",
    "from nnlar.datashaper import DataShaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries if they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes (1999995, 5, 1) (1999995, 1)\n",
      "shapes (899992, 5, 1) (99995, 5, 1) (999998, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "from nnlar.datashaper import DataShaper\n",
    "ds = DataShaper.from_h5(\"../data/rdgap_mu140.h5\")\n",
    "\n",
    "x, x_val, x_test, y, y_val, y_test = ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 1\n",
    "integer = (3)\n",
    "\n",
    "def bit_lenghts(i):\n",
    "    #To change to create models with different bits parameter by defining the smallest bit lenghts \n",
    "    #Example : bits 8 ==> (i+4)*4\n",
    "    return (i+4)\n",
    "\n",
    "def bit_width(i): return {'bits': (i+4), 'integer': integer, 'symmetric': 0, 'alpha':1}\n",
    "\n",
    "bits_range = 1\n",
    "\n",
    "nbr_epoch = 15\n",
    "\n",
    "def units(j): return (j+5)\n",
    "units_range = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saving(model, j, i ):\n",
    "    if (i == None):  \n",
    "        rmodel_json = model.to_json()\n",
    "        with open(f\"r_models/r_model{units(j)}.json\", \"w\") as json_file:\n",
    "            json_file.write(rmodel_json)\n",
    "        model.save_weights(f\"weights/r_model{units(j)}.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "    else : \n",
    "        qmodel_json = model.to_json()\n",
    "        with open(f\"q_models/q_model{units(j)}_{bit_width(i)}.json\", \"w\") as json_file:\n",
    "            json_file.write(rmodel_json)\n",
    "        model.save_weights(f\"qweights/q_model{units(j)}_{bit_width(i)}.h5\")\n",
    "        print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model(unit_j, bit_i):\n",
    "    if (bit_i == None): \n",
    "        with open(f'r_models/r_model{unit_j}.json', 'r') as json_file:\n",
    "            json_savedModel= json_file.read()\n",
    "        model = tf.keras.models.model_from_json(json_savedModel)\n",
    "    else : \n",
    "        with open(f'q_models/q_model{unit_j}_{bit_i}.json', 'r') as json_file:\n",
    "            json_savedModel= json_file.read()\n",
    "        model = tf.keras.models.model_from_json(json_savedModel)        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " SimpleRNN (SimpleRNN)       (None, 1)                 3         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2172/45000 [>.............................] - ETA: 36s - loss: 8.6808e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25129/1184363907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25129/1184363907.py\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0munits_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25129/1184363907.py\u001b[0m in \u001b[0;36mnormal_model\u001b[0;34m(units_parameter)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;34m\"\"\"Updates the progbar.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_init_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# One-indexed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           unit_name='step' if self.use_steps else 'sample')\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_stateful_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful_metrics\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_implements_train_batch_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m_update_stateful_metrics\u001b[0;34m(self, stateful_metrics)\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_stateful_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstateful_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def normal_model (units_parameter):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                    patience=10, \n",
    "                                                    restore_best_weights=True, \n",
    "                                                    min_delta=0.000001,\n",
    "                                                    mode='min')\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                patience=5, min_lr=0.000001, verbose=1)\n",
    "\n",
    "    r_model = Sequential()\n",
    "    r_model.add(SimpleRNN(units_parameter, input_shape=(5, 1), return_sequences=False, name='SimpleRNN'))\n",
    "    r_model.add(Dense(output, activation='relu',name='dense'))\n",
    "    r_model.compile(loss=\"mean_squared_error\", optimizer=Adam(lr=0.001))\n",
    "\n",
    "\n",
    "    r_model.summary()\n",
    "\n",
    "    r_model.fit(x,y,validation_data=(x_val,y_val), epochs=10, batch_size=20, shuffle=True, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "    return r_model\n",
    "\n",
    "def model_training (): \n",
    "    models =[]\n",
    "    for j in range(units_range):\n",
    "        units_parameter = units (j)\n",
    "        model = normal_model(units_parameter)\n",
    "        models.append(model)\n",
    "        model_saving(model, j, None)\n",
    "        print('number of units ', units_parameter)        \n",
    "    return models\n",
    "\n",
    "models = model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 12:58:05.036680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-29 12:58:05.037073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037390: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/sft.cern.ch/lcg/releases/gcc/9.2.0/x86_64-centos7/bin/:/inteltools/altera/21.1.0.169.pro/gcc/lib64:/inteltools/altera/21.1.0.169.pro/hls/host/linux64/lib\n",
      "2022-04-29 12:58:05.037504: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1867] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-29 12:58:05.037744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_simple_rnn (QSimpleRNN)   (None, 1)                 3         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/atlas/bonnet/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10318/28125 [==========>...................] - ETA: 17s - loss: 0.0054"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10698/97332447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mqmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mqmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10698/97332447.py\u001b[0m in \u001b[0;36mqmodel_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mbits_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbit_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0munits_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mqmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbits_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mmodel_saving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mvar_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10698/97332447.py\u001b[0m in \u001b[0;36mquantized_model\u001b[0;34m(bits, units, original_weights)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#using the weight from the classic network as a base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mqr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mqr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbr_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mqr_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def quantized_model (bits, units, original_weights):  \n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                    patience=10, \n",
    "                                                    restore_best_weights=True, \n",
    "                                                    min_delta=0.000001,\n",
    "                                                    mode='min')\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                patience=5, min_lr=0.000001, verbose=1)  \n",
    "    qr_model = Sequential()\n",
    "    \n",
    "    qr_model.add(QSimpleRNN(units,\n",
    "                        input_dim= 1,\n",
    "                        activation='relu',   \n",
    "                        kernel_quantizer=quantized_bits(**bits),\n",
    "                        bias_quantizer=quantized_bits(**bits)))\n",
    "       \n",
    "    qr_model.add(QDense(output, \n",
    "                        activation='linear',\n",
    "                        kernel_quantizer=quantized_bits(**bits),\n",
    "                        bias_quantizer=quantized_bits(**bits)))\n",
    "    qr_model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "    \n",
    "    qr_model.summary()\n",
    "    \n",
    "    #using the weight from the classic network as a base\n",
    "    qr_model.set_weights(original_weights.get_weights())\n",
    "    qr_model.fit(x, y, validation_data= (x_val,y_val),epochs = nbr_epoch, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    return qr_model\n",
    "\n",
    "def qmodel_training (): \n",
    "    qmodels =[]\n",
    "    for i in range(bits_range):\n",
    "        var_units= []\n",
    "        for j in range(units_range):\n",
    "            bits_parameter = bit_width(i)\n",
    "            units_parameter = units(j)\n",
    "            qmodel = quantized_model(bits_parameter,units_parameter, read_model(units(j), None))\n",
    "            model_saving(qmodel, j, i)\n",
    "            var_units.append(qmodel)\n",
    "        qmodels.append(var_units)\n",
    "        print( 'bit width ', bits_parameter)        \n",
    "    return qmodels\n",
    "        \n",
    "qmodels = qmodel_training()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(bits_range):\n",
    "    for j in range (units_range):\n",
    "        qmodel_json = models[i][j].to_json()\n",
    "        with open(f\"q_models/q_model{units(j)}_{bit_width(i)}.json\", \"w\") as json_file:\n",
    "            json_file.write(rmodel_json)\n",
    "        models(i).save_weights(f\"qweights/q_model{units(j)}_{bit_width(i)}.h5\")\n",
    "        print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS CONVERSION of the keras model, every layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 17s 550us/step\n"
     ]
    }
   ],
   "source": [
    "y_keras = r_model.predict(x_test)\n",
    "closs=mse(y_test, y_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEFCAYAAADuT+DpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAy6UlEQVR4nO3dd5wTdf4/8Nd7G7AsvUtbmihFEZdqQUABRQV717Ocnp56P8spnB42VPTO0/uecoq9nr2gIEhTFKUsRTrSYQHpvWz9/P7IJDuZzCSTZJJMdl7Px4MH2cnM5DPJzOf9afMZUUqBiIi8KyPVCSAiotRiICAi8jgGAiIij2MgICLyOAYCIiKPy0p1AmLRsGFDlZ+fn+pkEBGllfnz5+9SSjUyLk/LQJCfn4/CwsJUJ4OIKK2IyEaz5WwaIiLyOAYCIiKPYyAgIvI4BgIiIo9jICAi8jgGAiIij2MgICLyOAYCIiILSil8UrgZJWUVqU5KQjEQEBFZ+Hbp7/jrp4vx72m/pTopCcVAQERkYf/RUgDA7kMlKU5JYjEQEBF5nCOBQESGiMgqEVkjIiNM3j9TRBaISJmIXGp47wYRWa39u8GJ9BAROamqP9E37kAgIpkAXgJwLoBOAK4SkU6G1TYB+AOADwzb1gfwCIBeAHoCeERE6sWbJiIiJ0iqE5AkTtQIegJYo5Rap5QqAfAhgGH6FZRSG5RSiwEYu94HA5iilNqjlNoLYAqAIQ6kiYiIbHIiEDQHsFn3d5G2zNFtReRWESkUkcKdO3fGlFAiolgoVO22obTpLFZKjVNKFSilCho1CnmuAhGR48QjbUNOBIItAFrq/m6hLUv0tkRE5AAnAsE8AB1EpI2I5AC4EsB4m9tOBjBIROppncSDtGVERK7BUUMRKKXKANwJXwa+AsDHSqllIvK4iFwIACLSQ0SKAFwG4BURWaZtuwfAE/AFk3kAHteWERGlnDg8buhYaTl+XO2+Pk5HnlmslJoIYKJh2Sjd63nwNfuYbfsGgDecSAcRpb9Vvx9Eq/q5qJGTmeqkOO7vXy7FJ/OLMOWeM9GhSa1UJycgbTqLiajqO1RchsEvzMRfPlyY6qQEcaplaO3OQwCAA8dKHdqjMxgIiMg1/LN8ztvgkhZijhoiSrxdh4qx93DVntCLyMhtnc+O9BEQxapg9FQAwIYxQ1OcEnITl+WTjhGX3pjAGgERuYY7s0n3leCdxkBARGQhUYHJbXGFgYCIKEncWuNhICAi13FbUwwnnSMiShK39aUmqnPXbYGOgcABZeUV6PXUVHyzeGuqk0JELua2QOfHQOCA/UdLsf1AMUZ9tSzVSXGV135ch6vGzU51MigNKbcVmV2WHKfxPgJKmNETVqQ6CZRmnJ7kLV4JGzXkskDHGgERUZK4LdD5MRA4wF2xnSj9ue2aclt6nMZA4CB3xnqiNOKyiyhRnbtuCywMBEREyeKyQOfHQOAAl/X7EJHD3Na56zQGAge5dYwwUdpxSb6bsKYhlxyfHwMBEblGVS9MufXwGAiIiCJwWQHecQwEDqjqE1IRJZtbrqhEjft3W57BQOAot1b8olNaXoE3Z61HWXlFqpNCHlM1riBrbm36YiCgEG//vAGPfb0cb/28IdVJIaIkYCCgEAePlQX9T5Rsbhuu6Xhy3HV4DASOcNmPSpSu3PZwd6eTw7mGPMBl53DcGN+IvIGBgEJUtYBG3rHjwDEc//C3WFK039H9VvGWIQYCJ7jtRyVKd7FeUz+u3oWSMt+oNzdyayGLgcBBLv2NY+eyDrt0dtqY6bh47KxUJ8P1qtw1lCYYCCiEWzu03GrNjkM4XBx+hNWWfUexYNO+5CSIHOf0KCa3lbEYCMiS/1xdu/MQby4L4+x//YCb356X6mRUKW7JKJ0excSmoSrMLSetU/Qna9HeIxj43A94+tuVqUtQGpi9bk+qk1AluDWjrOocCQQiMkREVonIGhEZYfJ+NRH5SHt/jojka8vzReSoiCzS/r3sRHpSpSqexHsOlwAA5q5nRkfpw+2jfNw211BWvDsQkUwALwE4B0ARgHkiMl4ptVy32s0A9iql2ovIlQCeAXCF9t5apVS3eNNBzqtqNR2j4rJy5GRmuO4mJoo9o3T+BjCn9+fOc82JGkFPAGuUUuuUUiUAPgQwzLDOMABva68/BTBQqtDV57boHq8q88OEUbT3CDo+PAkfzN2U6qSQjlszyqrOiUDQHMBm3d9F2jLTdZRSZQD2A2igvddGRBaKyA8icoYD6UkZnsTpY/2uwwCAb5f8nuKUUFpwuKznttp2qjuLtwFopZQ6BcC9AD4QkdpmK4rIrSJSKCKFO3fuTGoivaqq1XTSwabdR/Dzml2pTgZpHG9qcmlZ0YlAsAVAS93fLbRlpuuISBaAOgB2K6WKlVK7AUApNR/AWgDHm32IUmqcUqpAKVXQqFEjB5JNVsxOVgaF5DjzHzNw9WtzUp2MlHNbibmqcyIQzAPQQUTaiEgOgCsBjDesMx7ADdrrSwFMV0opEWmkdTZDRNoC6ABgnQNpSqqqfNKyuYvSkf4GsK6PTsZ1r8cXXOMpCB0tKcfSLcFzH7kty4g7EGht/ncCmAxgBYCPlVLLRORxEblQW+11AA1EZA18TUD+IaZnAlgsIovg60T+k1IqbccpurXaF6uqHOCoajK7Bg8eK8OPq2Nrbvtq0dY4UwTc+/EinP+fn7DvSEnc+0qUuIePAoBSaiKAiYZlo3SvjwG4zGS7zwB85kQayDlVaEAXxWHv4RJUKIUGedWS/tlWZZDpK7fjprcKMfXefmjfOC/h6ZiyfHvc+1iwaS8A4Fipe+/OT3VncZXgxoLzPyevwuUv/5LqZFAaO+WJKTh19NRUJyPIhMW+UV4Ltcw1XbntCWwMBA5yUzn6xRlrMHdDfK1s+lPVZeetLbe9W4j8ERMS+hl2Luh0z7TcKNmno1Pnv1tr2wwEFJbpCCKlsOr3g8lPTJQmL4u/Wu+Ei8b+HPU2U5Zvx7HS8gSkJtSBY6WBqURcwyLjDZyPETLmNCy3pBQDAUXt3dkbMfiFmfhl7e5UJ6XK+uM7hRg9YXnkFR1Q8MRUdH9iSlI+K16RytPpMsrNbYGKgcABbmvvc4rVYfmHwm3acziJqfGezXuO4v05G/HdssTd/VxSVoGSNJxiPNn3tRivhXs/WoSvFhlvl4rMrWGKgSCMXYeK8VMUw86cbP/7YmER8kdMwNZ9Ry3X2Xmw2LHP04t0GFU07rmOCPDQF0tx67vzE/YZZzw7PWH7TgT/uZnqc/DzhVvwlw8XpTYRDmIgCOPyV37BtXHeiBKrzxf4Shurdxwyff+rRVvQ48mpmL8xuEO4vEKhuCw5bcvpUg13yl63taM7YPuBxBQm4mVV4nfynCsrr0hdX5fLClOeDAQTl2yL+GhBAFi3017TRzJLJ2XlFfhm8VbM0Z4PsHxb8In8x3cK0fHhSY58lv5i1B+jy87hpPhq0Rac8sQULNq8L2h5In97b4XZ6DjxtT835TcMfmEm1uyIHAycaopy6aAh7wWC5VsP4I73F2Dk50tSnRRbjOfNaz+tx50fLMTX/jseDTnR9JU74v7M0jLrk37fkZLK0SwuPakTwd8MsGzr/vArOsitQw3jMWnpNuSPmBDzKCW7TUN2AvQi7RnSbq0VJZPnAsEhrSYQru3dypx1u/HzWus+g7KKCrw5a73l832L9h6xfQFYncjbDxwDABy0UaOJ1fNTf7N8r9vjU/DN4m0J++xYlZRV4M4PFmDdTvOmtHj4v3MAWLBxn+P7t6IPA/uPliZtOGkkSqmoB0iUlVcgf8QE/Om9BQCA1dvDl8Ktdh8pNkYTO1MZZ401jGOl5SkddOK5QOD/sqM5Cd6atR7lFQpXjJuNq1/19RnsOVyCDw0PNdl+oBiPfb0c7/yy0XQ/pz8zAz2ftHen5k/aVMTGdCayXb68wnAiRjgv9SmZtHRbTMHVKQs27cU3i7dhxOdLsGXfUUdv4tK3I3+2oAjb9h9FaRwjbeas2438EROCJiJTSmHbfuvv7+THvsOlL0d/P4LTisvK0WbkRDw/xbqwYOZwibNBLJ6mmqVb9uOC//yEo1pgtZP/RpNHz/xtZ8gkc35mV++x0nKc8PdJGDMpdc8F91wg8IsmQ3306+X4pHBz0LK/fLgQIz5fgs/mF4Wsf/CYdWm9zJjZ6qzbeQj//X5taIYchlNliOkrt6Pd3yZi7PdrbG+jb7r403sLcNHYWQ6lJlhZeUXEEqTeaWOmx3QTl119np6Oh76IvWnRP3+N/j6Ml39Yhz5PB4/gMRYClm45AABYUrQf+SMmYNPuIyH7XrR5Hz42nKuxWGtRszpS7Ms835ltXtjxm7FqB4r2hqbPL/bz1vy6XbPjIPJHTMDUFZGbRp/4ZjmWbNmPxUX7tbTYS01xWTlemPpbxJrZ9W/Mxfn/+cnWPoHKVopPCouw70gJ8kdMwPhf45/sLhqeCwSxnoDGzH3XIV8Tz32f/Bpx2/P/8yNOf8Z6mN7Xv27FkxOW44pxs/HMpJU4cLQ08J4xYCWqOvvGTxsAAM9OWhXzPpxuay0u81WX//HdKpzz/MxAs8/8jXuQP2ICVv5+IGSbueudmbx2854jeGHqb5bVdSf6YvRmmT6MJvTHPlxchv+bvhoA8P1voWkY/tIsPPDpYrw5a33gKWzzN+7B9JWVd1mXlVdg8x7rTBoABj73g+lyq+tn2db9+H8fLgwUYm58cx7O/lflPqI9byNdp8afZYHW3j95qfU9F/60+TeN9lJ6a9YGvDB1NV7/ab2t9XccOIbdhyqvCX0AMTutBMA67Td746f1KC2vwAX/+SkpDyryXiDQnQUlZRV4auIK7NdlvFYqwtQNn5q4Iuy2S7ccQNHe0Gr/b9sPorxC4a7/LcSrP67HMa36HO6zjKJtVpyzbjfeMynN/WRysimL136JbGLdf6QUHR+ehLHfr0XhBl8zz26tf+VSbTK9N3QXpJPNq4eLy3DGszPwwtTV2Lj7SNhMLNLHTlpq3Z+iL4ma/eZmn3vR2FmBGkVxaYVlf9RjXy/HZVpT0iX//QU3vVUYeO+piStxxrMzgvo+7Pp0vq+2se9I8DVzx/sL8OWirUEB5lipr1/gutfnOHauBDqLtb//OXkV8kdMQFm5+S9x4FhlOudv3Bu0cYa2M6WAT+cXYZeWaU9csg2LNu/DUV1zlgJQXOb7ro/abObq+dS0oEn7zvrn94GMXs/s3FUAivYexZIt+zEyjtqnXZ4LBLsP+37suev3oM/T0zBu5jqc/Nh3YauxgG+0jpVvw5RCzOSPmIBnJq3EoOdnYsy3lUFEGf4HQjMDu6URK1eMm42Hv1wKACgtr8CNb87FpybNW8bPX7EttPQN+I7l8lecneV07Pdr8MYs33F+Nr+osl9He99/4WzSZTpvzorve9F7QddZrgCLTCY0a+vz9DSM/Hxx0DJ/52jQlia54s82p+v4bXtlk82TE1fgkv9aN4FZNVH6ax97DfPjW5U8lVKBPpfVus/PHzGhMnPVjP1+TVDtAwB+XL0rZATUxt2HTTPUd2dvME0DAHwwZ1NITcb/uxvvnfH/YvqbLiu0Tu7AZIxakq5/Yy7u/+RX3PbufOw4eAx3vL8Aw1+ahRNHVQ7DnrJ8e2Cgx39/WBv0WXsOl+DisbOwdd/RiDWtjVpz3vtzfP2L+4+W4v05voKZSPBZ5T/vN+4+EleflB2eCwR3frAw8Hq3bgTP81NWh90umrt4FRT2HC7BA5/+atme+N/vfSeTfgSOv63QqnR7y9uFIcuWbtkfc5vw+l2HMWPVTtxvo3nLzFs/bwAQfXPM0ZJyFIaZGfXZSavw72m+32PdrsOBav/Iz5eg66OTTbf5LsZ543ceLMbLP6wNagI6osugBJUlQb1dh0LPh237j+F/czdj2ort+Lhws+UNaKUWpVcjO6XoX4v2Y14Us8zuOlSMg8fMa8DLtx0wPc9vemseLhr7M2aYNIe9+8sGzFqzK5DBfVxYFFT78Lv9veC7ox/8bAlufz942a+b9+Gpib4OU2M/WXmFwt++WBJ4wMzWfUcx5tuVgU7owPqGLy3o/hcV/KCZDMO68zfuRc8np4Wk3c9/vhvT9vmCIizYtA+v/7QeN7w5N2Q7sy6/6St34Pf9xzDy88V4Yao/76lM0K6DxRj8wszA3x0e+jaho8YceTBNurC6AADfaJDRw7ugWlYGMjIEH88Ln7lGGur1z+9W4ePCIpzUom6E/YQum72usnTov/Htt+0HMXVFaGb3yfwifDK/COd1bWbaTDB52e/4dH4Rbj2zLXrk1w8stxPYjMdovAlvicXIiEWb92Gybn6cb5dsw7ldmwHwNcfd/8mvmLBkG34eMSCwTkWFwpQV2/H9qp2W6THeZV2hfBel8YI2WrvzEFrWy0VOVmi5Z9X2gxjz7Uqc3r4hjpWWY/m2A4HSGuArpRkzLL9/fbcqcGOf3s1awG5et4bpdv4MBQDe+WUDvrOYJXWVzQ7yF6b+hvdv6R2yvLisImRiwAJdU4Wx/2n0hBUYPWEFNowZGrR8hvabWKXnGhvPWDZ7QtjM33z7nbFyBw4Wl+Hu/y0Mev/3/cfQtE510/35C1L6tBsppXDuvysz0/dmbwx60IzTI/DKyitMb0K1utZ6Pz0NvdpUXpO7DhVjuVbz3mIyAu9wcRmqZ2c6lNpgngoEfceEn1flxFGTcF3v1nhieBc88Nliy/U6j5qEejVzLN//ee1utGtk7+lJv5u0096luyD888wM63Zc2P10ecS8pHybtv2U5duDLvAeNoaxjv91K6bpRmF0tvgMvXs/XhSYHsPv9vcX4NlLToKCwoOfVbZ36oebPvjZYnwSponKzNz1e9DrqWk4q2OjsOsNfO4H1MvNxsJRg7B131H0HTMdd/ZvH7ROWYUK9D3oVSjrGtr/TQ8/wsrsYv59f+Xv7S/9WtloMirIjD9D221SS7nq1dmB16/9aO9x4G1Hmj/DYcW2A8jODA6mX8bxKMcKhbDPi3hl5lo8ckFnAMAWkz62SPYcLgmqfU1YEtxf48TAi427D2PDbl/m/7bFsPFoPPTFUsv3PpizCXcN7BD3Z5jxVCAIN6zT793ZGzHqgk5h1zlcUo7DJdYn5tz1e3CkxNkbvpx4dmq0fKOAohsJZAwCfmaBVZ/xRhsE/HYdKg7bx+G390gpJi/7PRAYX5xhb5jsZQ6P3e/9tHXTQ6z8Hf0XRBiyaCw165se9KxGLyf7HHxz1gbUz83Bc1HeswAgYp8fENwEGKt+//g+ru2jCUbPTfkN783ZiNkjBzp+17nn+gjsuPDF+MfD+8d8u2lenkTcdZtObgszi+fwl8x/c/8wYbfbuu8otu6PfhSQ20UbBEq0/pyFm/ZFdT9OqsxeF13/2vYDxZaBOh6SjnPpFxQUqMLC0A6pSBL92EIiokRb+9R5yIzUMWZBROYrpQqMy1kjICJKI4kovDMQEBF5HAMBEVEaScT05AwERERphE1DRETkOAYCIiKPYyAgIvI4BgIiojSSiDu/GAiIiDyOgYCIyOMYCIiI0kgiZgViICAi8jhHAoGIDBGRVSKyRkRGmLxfTUQ+0t6fIyL5uvdGastXichgJ9JDRET2xR0IRCQTwEsAzgXQCcBVImKc0P9mAHuVUu0BPA/gGW3bTgCuBNAZwBAAY7X9ERGRCZWAcUNO1Ah6AlijlFqnlCoB8CGAYYZ1hgF4W3v9KYCB4pswYxiAD5VSxUqp9QDWaPsjIqIkcSIQNAegf8BvkbbMdB2lVBmA/QAa2NwWACAit4pIoYgU7txp/VxbIiKKTtp0FiulximlCpRSBY0ahX9GLRFRVZWT6Xy27cQetwBoqfu7hbbMdB0RyQJQB8Bum9sSEZHGrdNQzwPQQUTaiEgOfJ2/4w3rjAdwg/b6UgDTlW8u1fEArtRGFbUB0AHAXAfSRERENmXFuwOlVJmI3AlgMoBMAG8opZaJyOMACpVS4wG8DuBdEVkDYA98wQLaeh8DWA6gDMCflVLl8aaJiIjsizsQAIBSaiKAiYZlo3SvjwG4zGLbJwE86UQ6iIgoemnTWUxERInBQEBE5HEMBEREHsdAQETkcQwEREQex0BARORxDARERB7HQEBE5HEMBEREHsdAQETkcQwEREQex0BARORxDARERB7HQEBE5HEMBEREHsdAQETkcQwEFjKcfyyopxzfJC/VSQi4e0D7oL+b1q4eeH1yizrJTg6R6zAQWLjptDaO7u+2M9s6ur9UePaSkyzfa1U/N+jvl67unujk2Fa/Zk7Q30O6NE1RShIvAc81pwSZfl8/XFHQEjVzMlOdFAYCKxXK+r2nL+4a9f5Gnndi4PWq0UMirt+sTvWI61jJNFRnXru+IOZ96XU6rrble9f3aY1ZIwY48jlOy63meyJrq/q5+NflJwe/GSHnPKNDQ8fTM/SkZjFv+8gFnSzfO75JHtY/PdTWfh7SnY92/d9Vp0S9jZMa5lUL+vu09g0c/4yHh0b/vegZrz0rl53aAm0b5eGZS09CfsOacX2mExgILFQo60jQ5bj4mhOqZUUuAUy9t59pJnTpqS1Q0Lqe5Xa3n9UOq0efG7SsXWNnmmnCfCUQETSvW6Ny3Sj3netwqeirP58WsqxHfn1c3L1F0DKzy/a8rpU1Bju/VbSssgqrgN1e9/tddErzwOvRw7vEnIZ6hlrSp3/qg6n3nhk2SF148nGW7zXMy7F8LxqNa/ky+wY1c7BhzFCcpDXd3T2wA+Y9NDBo3bFXn+rIZ+rVqZEd1fp92zXA1Hv7Bf6+5Qx7LQlX9WoVeK0vi/RqUz+qz3cKA0EMWtavzPCMTSJGU+/tZ3qBh8v4vrvnTNSslmVa81AqfCH2wSEnIMNQKklGa4HxM8IFDTMnNK0V9Lc+qMTi5JZ1Ld8b1KmJ7f0koqlFLHZ6tkW69GvXza3McE8NUyCImAbD3zVyMtG+ca2ITaJ/tMjojM1vQGVfzMe39cGbf+hhK11ZhnPXnzEP7twk5Hurkxtdpq1ndRzhDOvmC4Rnn9g4sEzEcI5EWwICIFFcoYmoBQEMBJZUmJysbm4Ohnb1lZzO7Rq+vbl94zzTC3zO3wZalgBrV/ed4GYZxtW9Wob9PDMt6+cG0hurbi3rQoU5y41JDbeuFX3mb6eZaXBn+xk6UJnGvu0b4rPb+waWDelsr8/g+Ssqm5WOi6PpzqnYYvzObz+rneW6fxnYAZfoakP+bc/q2Aijh3dBZ62WG2twycwIzUqm3tcPb/yhAD3b1Ef/ExoHvTfqfPMmLuM5/8IV3fDIBZ3QqZmvWTJDfLWDDWN8TWDnhbn+Ztx/Fs7RXXv6dR8aav754c7aJ4Z3weDOTTDq/M6V6XXg19Qfsv7zzQpD0Raw7GIgsGD3+47mRGjbqCYu7u6r2teqnh0UINrq2gn9J4ZZZnNq6+iqjlf1bGW73fIfl1p3BmdI8En4zCXBtZVwn2B10Ru1bmBduxrW7biQDNvYRHfz6W0w/b5+mGtoQujdxleK8n/3PpUHU5Bvnfm11tX4LjqlMiP9eeRAs9VtMasQrH7y3JBlXZvXQcO8HNzWzzqD19OnDwC+uev0wOt7zjkez+n6R/xpqFsjG9f2bh12vx0a56Fr8zradqGJv7Z3K9PfP69aFgacUHmO33vO8SHrDDAECKMGedVw42ltAp+77umhQfuxuv7aN85Dm4Y1cXlBcMEpXLMqgLAXfrWsDLxyXQFa6c7T0cO7BKfAJDmROoMb1zIvVHxxR9+w2zmJgUDzqKETLlwfgV7bKDp6pt93Fv51eTfb64tIUPujv6odTfCxatr46NbeISXq87o2w9hruuPG0/IDy6pl+U4RheBrxHjyGjMI/ddXr2bsVfjgz7B+b8mjg/Dw0BPRtlFeSNpaNcjFhjFD0bddZZ+LP30CXwCZ+df+lZ+j+37vG9QRgP1OwGg8MKRj4HV2pu971o8uq1czB4UPnxMoDft1bFLZjObvQNWfJ35dmkfuy7Jzlk+5tx++1oJKjezQTO2qnq0wSDuXXr62O/7QNx+fm2Ridw/sELLM2LQabVPc3y0KGaeYNA0qBbx1U09MuedMy/1FW5PNb1jTsqnPrkcvrDwG/SARs5T0yE9MHwIDgcbYfKPPyHKyTL4m7bevoYv21bNj/zr/OrgyU9CfVu0b5wVGMhg78uxkTlZr9GrbAHcNCL4wRXzBoGaOb5RNTmYG/n1l5UgRfXNZ/xMa480be+Cqnq0C21rp0LiW9Zs6XcNkXKL7jDZa8NV/ZlZGRkwXpIhARIJKebV1HYbZmZH3OeHu0yOuo+fPTJvXrYEljw7C0scGB977s+GeBz1/P4pZZlW7Rlbgdc2czKBOZTOt6vu+w3DfuRmz5qfOx9XB3QM6YMHfz8GQLs3w6IWd0b2Vecn7ptPa4GpdRykQfH1F+xM2rVM9KKAa99nDUNvLq5aFDk2sz8ewAyIsriaz/pGg7SIclP96A4BnwgzRBnxNfInAQKBpUS8Xt5xe2YGkPx9m/rV/6LBD3Qr+Dq3MOEoG53ZtVjk8ztjebnFyvnWjvQ44K8bk+k90//I7B7RHI20Uh1KhJZT+HRsHbrwzHnlLXUmvS/M6KHz4bIwe3iWouULvtn7tgoKhUV71rED6wvXf2BVuDwWt6+G4OtVx/knNbJUPO1uMIntiWGd8eGvvkOUjzzsRt5/VDkO7NkOt6tnIq1aZEZgdmlUpVSC46BRfB6Z+H8seH4Lnr+gWNs2ntq6H7+45Ezfrznm/cJ3p1U1qBACQkSERM0QAGHVBJzx1UddAgM3JykDhw2fjVa2/zIk2d726uTkYe429e1r0g0CiUadGtmltB/A1m9lVNzcb1bMzAyOnzBgHgjiFgUBHf7lddmple2vTOtVDhh3q6UuE8dUSbWZw2mdkZ2bg1gg3qnUIM3TUzkWnPx6ztZXZigjOmABfE8a1vVtbNlcM7twUWZnmp+MDQzpixLmV47ud7C8zO6YLux2Hn0cOxIu6m+Ji+Vm7t66H3m1DR3nUqZGNB4ecYHm8VsxKliPPPRFLHxuM3Jwsky2AP/VrF9TUp3d8k1qm+9R37JrVLOKp+fpd3qMlbuvXFncP7IDa1bNRP47mQyeDx5AuTdGpWW3Tvotw17ZZkxkAjB7eNWLq7J7PxvsonGR+9lRxedWycKi4DLWqZeFgcZnpOvVyQ0s3//tj78q+A92vG+3YYyuVuzYM/wxzJkUqhd3QN9+3bxunW7jPUQBOblEXt/Vrixv65AeW+zvCqps1nznkjrOCm0sC31McUTdcpSI7ygw6ls+wUqdGNnrm18fcDXts7ScjQ0KCrt6Ic0+IOg3+b/WKgpZ4xmQAwconzsU7v2zAqK+WRb1vv2pZmRipC+7++zUa5OVg054jMe/Xz+wri/R79O/YGHVzczDxL2fg0fHhj+38k5qhf8fwHd3RinQ2271HIRaeDATzHjobx0rLkSGCkx//znSdWtVDv5o+7cKP4RXxZeHxllidHLseLrMMaRoyWVW/KCNDgi5ewDcapW5uTsQ2aUdoiYllaKqRv3kp0ncdbWb+/BUn49WZ67F82wHT9/PDjIzyu6N/O8x9c0/Icn9SM+I4Qb6750wcKSkPu47Y+J6v75MfVyAw6nxcbTx1UVf0alsfA5/7IapfONLXYefb6pFfL+LoNv1+XjRMoXJKq7oAfDeEvfLDuugTYMJ47vn74xLBk01DNXIyUa9mjuUNKdf3aY0GEaph12gdXsahh9GWUs/XdQDHkr3FEzOiSqpFjpibk4U/928fdTNHLPzJdXIstd1mBbPvqm5uNvoaCgfGIZxGZk1F0Xr52lNx02ltwjb7WTm+SS10C3OzXaqICK7u1Qp1Y6hdO1FualqnRsRzONxp17ttA/z6yKCg4bKxMjvXXrq6u2MtD2Y8WSOwck2vVvhq0dawN+b49W3XMHBTy8FjpSHvt26Qi427I1dxX7y6O1682vc6UEq1md5YMsTnrzgZQzr7gs9xhhtWjJmi7y7mxHROxcOJQOBELFk0apDp8kCJ2qGAVdkU5vs/v2FNjAoz55BTEnXzUjKkIu1WGbX7rqBQDAQ6bRvlofDhs+PaR7WsDBwpKccnt/VB0b6jUW3rP3etMl+T7gnbGtT01XDq5uYEhrzWrp6NDWOGYtqK7Xjtx/WBkRxhO4WTTD9IIlxQqhHrXEUJuEqNyRzcuQkmL9sOIL4MKlkxOTA6KzkfF7dI34t/uOjAE+236Ztl6on6+v3TzVzRI3FNP5HEFQhEpD6AjwDkA9gA4HKl1F6T9W4A8LD252il1Nva8u8BNAPgzzEHKaV2xJOmcAZ1aoLS8opE7R4A8MUdp+G7Zb+jce3qaFw7tmkIojnh7GYOfzvvRJzYrDbOOr5RyHsDT2yCgSdGnucm2eb+bWDwGHMH922WId81oD3mrA9um4+nP8K/7SvXFSB/xISY9+dEn0hUHK7RpFr7xnlY/rj1yCozd/Rvh4Z5Ofi7A/0gkWrV1bMzsWr0EOQkoXnVSrw1ghEApimlxojICO3vB/UraMHiEQAF8BUy5ovIeF3AuEYpVRhnOmwZF+V0zG/f1BMfz9sc1TYdm9ZCx6b2bqAyivbC02cQF5/SHPfrxuHPf/hsFJdVBr0aOZkhN/IkMm1OsAqkdu8j+PLPp1mOQPF/d/pL1H8XsZmo7uYOs25cNYIkhWW7n/LBLb3w45pdCU2LHXa+l0hBwLiHalmZuK5PflAgiLaZ9O2betpeVz/L7ZiLT8LT365AA4dmdLUj3kAwDMBZ2uu3AXwPQyAAMBjAFKXUHgAQkSkAhgD4X5yfnXD9jm+EfiYl6ESxO5LF7P36NXOC2vwjdXbb5aYugsrRLMF/W+nWsm7EjtFEHp/TfQTJFqkm0rd9Q/Rt7/zzGpzhzJfWoXEeVu845NujUoimXurPO6I9x/qf0Dhkkr5Ei7cu0kQptU17/TsAs/aF5gD0xeoibZnfmyKySET+LmFCrojcKiKFIlK4c+fOOJPtbsYSjn+4oNlNhYksJSqowJh6s+G0Zro0rx324SlO0GeMV/ZoGdOUwnbziVgy4Uj3Y8QqaX0Exojrcon8Xm7UTcudjJFxRuFmV3VSxKtbRKYCMEvNQ/o/lFJKRKI9da5RSm0RkVoAPgNwHYB3zFZUSo0DMA4ACgoK0uQUjY7VQV3dqxXW7TqEu8823MaeqG9Bd2Wd0LQW/n5+p7APJdH75q4zEpQo3fBR3YGPiTA3S+R92sxFtNWeveQkdG4e+qS2f1/ZLeTmPqd+nmSf7G6oBMYyjci5XZoiQwQTlmyLvHKUruoZ/fTvfvF8n7f3a4+f1+6OeA9TvCIGAqWU5TAaEdkuIs2UUttEpBkAs47eLahsPgKAFvA1IUEptUX7/6CIfACgJywCgRc0zKuGg8fKYJzavXp2JkYPr5z2WZ95nardx3BaAh6pCPhKh2bz0aSCv6RqdQd2NGLNXC/vYZ4hDOtWWcmtvN8h9FPs5G8nNPUFmisMUygnK4POb+i76c3O7KVOi2W4sv9hNi3r5yK/QU1MWLKtynR0d21Rx3KYspPi7SMYD+AGAGO0/78yWWcygKdExH/n1SAAI0UkC0BdpdQuEckGcD6AqXGmJyWcOufev6UXflq9C7Wq279xpHurelj5xBDLycBSKTtTUFru/BXpxB6NY/MdFedOm9apHrhHBQDaNPDNFHpTkgLyqa3r47t7zozphrVUuLJnK2zccwR3DWiPbxY7XxuIhf9OY8A8uLktUMUbCMYA+FhEbgawEcDlACAiBQD+pJS6RSm1R0SeADBP2+ZxbVlNAJO1IJAJXxB4Nc70pFS8ecpxdWtYljjDcWMQAICZD/TH9gPFju0vIXcWR/jRcjIz0KJeDdwfZkSRUc/8evh18z7TScJiGQpaJzc7KDAkw/Fhpmp2m+rZmXjkgs6RVwzDyQLB+qfPc25nSRJXIFBK7QYQ8qgmbTjoLbq/3wDwhmGdwwCcf/o0uUazOjXQrE58zx4OErhY7Y2uCqdDE19p97JTwwfejAzBTw9Gfmym3oNDTsCVPVsFTcX9z8tOxv2f/Bp9QintGGsAbuhzicSTcw0Z9e+YvCGiTkpU7bK+NgeT2QysToq1lOtEjaBJbV/zy/AETJaXlZmBdo0smlVc1iRQVbmt6cXtPD/FRDpW4xI9jPC6PvnIrZYV9LBzN0i3qQ/00qFUWBW48Xt20704VjxfI/A/qpAqZWYILi9omZDn9Doh2sn53GDACY3Rsn4N2w+ip8QbmOSbtgDf40ndyPOBIJ15rfqbZvc5BalXMwc/PjAg5ulHvML/9LOz4nzoi51O+VeuOxVPX+wblp3YQoVv73MfGojGtRP3lLF4eL5pKB15tQLj0cP2lNycLMwaMQCNYpwiJZprIyszw5HHbtrm4hIMAwEl3YnNauP6Pq1j3t5rNSGvcWvzSazSoeDGpqE0lvTpiR3y7V/OiOmxe/7HYfbIrw8gPS4wSg03FRYGd/ZNwZYb5tnSqcZAkIaSNR2x2/Rt73sqXJuGkZ/7S97k9LXRs42v0HH+Sfbm2jLz6AWdMe+hs5HHQFC1Jbv04Z8JNMs4KZFHXHiyr2bgxPNhydtOa98Q2ZkSNMuoXvvGedgwZihOi2O67azMDDSq5c5OYj/3hqh0lKSC+tMXd8VJLeqid9v6yflAl+naok7Sp1ygqqlxrepY/WT63UvkNAaCNFQ3Nwe3n8Xx6ERWXNRFkBa82bZARFWTN7vP4sZAQETkcWwaopT67zXdg6bRPqNDQ1zc3fmJ4Mhb3DR8NB0wEFBKndu1WdDf797cK0UpoaqALUOxYdMQEZHHMRAQUZWTrnfdpwoDARFVGZxSPjYMBE5g4YOI0hgDgYNYFiGicEYP74LT2zdEl+a1U52UIBw1RERVRt92DQAAV8cwu20ydD6uDt67xX0j4xgIiKjKOK5uDc5DFQM2DREReRwDARGRxzEQEBF5HAMBEZHHMRAQEXkcAwERkccxEBAReRwDgQM4wRURpTMGAgdxwisiSkcMBEREHsdAQETkcXEFAhGpLyJTRGS19n89i/Umicg+EfnGsLyNiMwRkTUi8pGI5MSTHiIiil68NYIRAKYppToAmKb9beYfAK4zWf4MgOeVUu0B7AVwc5zpISKiKMUbCIYBeFt7/TaA4WYrKaWmATioXya+ntUBAD6NtD0RESVOvIGgiVJqm/b6dwBNoti2AYB9Sqky7e8iAM2tVhaRW0WkUEQKd+7cGVtqiYgoRMTnEYjIVABNTd56SP+HUkqJSMIG1CulxgEYBwAFBQUcuE9E5JCIgUApdbbVeyKyXUSaKaW2iUgzADui+OzdAOqKSJZWK2gBYEsU2xMRkQPibRoaD+AG7fUNAL6yu6FSSgGYAeDSWLYnIiJnxBsIxgA4R0RWAzhb+xsiUiAir/lXEpEfAXwCYKCIFInIYO2tBwHcKyJr4OszeD3O9KSEYkMVEaWxuJ5ZrJTaDWCgyfJCALfo/j7DYvt1AHrGkwY34QwTRJSOeGcxEZHHMRAQEXkcAwERkccxEBAReRwDARGRxzEQEBF5HAMBEZHHMRAQEXkcAwERkccxEDiAM0wQUTpjIHAQZ5ggonTEQEBE5HEMBEREHsdAQETkcQwEREQex0BARORxDARERB7HQEBE5HEMBEREHsdA4AD/jWQ1sjNTmg4ioljE9fB68qlXMwd/HdwRQ7s2S3VSiIiixkDgkD/3b5/qJBARxYRNQ0REHsdAQETkcQwEREQex0BARORxDARERB7HQEBE5HEMBEREHsdAQETkcaJU+j16XUR2AtgY4+YNAexyMDnpgMfsDV47Zq8dLxD/MbdWSjUyLkzLQBAPESlUShWkOh3JxGP2Bq8ds9eOF0jcMbNpiIjI4xgIiIg8zouBYFyqE5ACPGZv8Noxe+14gQQds+f6CIiIKJgXawRERKTDQEBE5HFVNhCIyBARWSUia0RkhMn71UTkI+39OSKSn4JkOsbG8d4rIstFZLGITBOR1qlIp5MiHbNuvUtERIlI2g81tHPMInK59lsvE5EPkp1Gp9k4t1uJyAwRWaid3+elIp1OEZE3RGSHiCy1eF9E5P+072OxiHSP+0OVUlXuH4BMAGsBtAWQA+BXAJ0M69wB4GXt9ZUAPkp1uhN8vP0B5Gqvb0/n47V7zNp6tQDMBDAbQEGq052E37kDgIUA6ml/N051upNwzOMA3K697gRgQ6rTHecxnwmgO4ClFu+fB+Bb+B6X3hvAnHg/s6rWCHoCWKOUWqeUKgHwIYBhhnWGAXhbe/0pgIEiIkhPEY9XKTVDKXVE+3M2gBZJTqPT7PzGAPAEgGcAHEtm4hLEzjH/EcBLSqm9AKCU2pHkNDrNzjErALW113UAbE1i+hynlJoJYE+YVYYBeEf5zAZQV0TiemB6VQ0EzQFs1v1dpC0zXUcpVQZgP4AGSUmd8+wcr97N8JUo0lnEY9aqzC2VUhOSmbAEsvM7Hw/geBGZJSKzRWRI0lKXGHaO+VEA14pIEYCJAO5KTtJSJtrrPSI+vN5jRORaAAUA+qU6LYkkIhkA/gXgDylOSrJlwdc8dBZ8tb6ZItJVKbUvlYlKsKsAvKWUek5E+gB4V0S6KKUqUp2wdFFVawRbALTU/d1CW2a6johkwVel3J2U1DnPzvFCRM4G8BCAC5VSxUlKW6JEOuZaALoA+F5ENsDXljo+zTuM7fzORQDGK6VKlVLrAfwGX2BIV3aO+WYAHwOAUuoXANXhm5ytqrJ1vUejqgaCeQA6iEgbEcmBrzN4vGGd8QBu0F5fCmC60npi0lDE4xWRUwC8Al8QSPd2YyDCMSul9iulGiql8pVS+fD1i1yolCpMTXIdYee8/hK+2gBEpCF8TUXrkphGp9k55k0ABgKAiJwIXyDYmdRUJtd4ANdro4d6A9ivlNoWzw6rZNOQUqpMRO4EMBm+UQdvKKWWicjjAAqVUuMBvA5fFXINfB0zV6YuxfGxebz/AJAH4BOtT3yTUurClCU6TjaPuUqxecyTAQwSkeUAygH8VSmVrjVdu8d8H4BXReQe+DqO/5DGhTqIyP/gC+YNtX6PRwBkA4BS6mX4+kHOA7AGwBEAN8b9mWn8fRERkQOqatMQERHZxEBARORxDARERB7HQEBE5HEMBERELhdpIjqT9aOaeJCjhoiIXE5EzgRwCL45hrpEWLcDfDfYDVBK7RWRxpHuHWKNgIjI5cwmohORdiIySUTmi8iPInKC9lbUEw8yEBARpadxAO5SSp0K4H4AY7XlUU88WCXvLCYiqspEJA9AX1TOFAAA1bT/o554kIGAiCj9ZADYp5TqZvJeEXwPqykFsF5E/BMPzgu3MyIiSiNKqQPwZfKXAYHHV56svf0lopx4kIGAiMjltInofgHQUUSKRORmANcAuFlEfgWwDJVPbpsMYLc28eAM2Jh4kMNHiYg8jjUCIiKPYyAgIvI4BgIiIo9jICAi8jgGAiIij2MgICLyOAYCIiKP+/+JPbiipl6lPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_keras-y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/atlas/bonnet/hls4ml/hls4ml/hls4ml/hls4ml/__init__.py'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "hls4ml.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rmodel_json = r_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(rmodel_json)\n",
    "r_model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: SimpleRNN_input, layer type: Input\n",
      "Layer name: SimpleRNN, layer type: SimpleRNN\n",
      "  -> Activation (tanh), layer name: SimpleRNN\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'SimpleRNN_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, 'SimpleRNN': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>'}}, 'SimpleRNN_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, 'dense': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}}}\n",
      "['Conv1D', 'SeparableConv1D', 'Conv2D', 'SeparableConv2D', 'DepthwiseConv2D', 'InputLayer', 'Dense', 'BinaryDense', 'TernaryDense', 'Activation', 'LeakyReLU', 'ThresholdedReLU', 'ELU', 'PReLU', 'Softmax', 'ReLU', 'LSTM', 'SimpleRNN', 'BatchNormalization', 'GarNet', 'GarNetStack', 'Add', 'Subtract', 'Multiply', 'Average', 'Maximum', 'Minimum', 'Concatenate', 'Dot', 'MaxPooling1D', 'MaxPooling2D', 'AveragePooling1D', 'AveragePooling2D', 'GlobalMaxPooling1D', 'GlobalMaxPooling2D', 'GlobalAveragePooling1D', 'GlobalAveragePooling2D', 'QDense', 'QConv1D', 'QConv2D', 'QActivation', 'QBatchNormalization', 'QConv2DBatchnorm', 'Flatten', 'Reshape', 'UpSampling2D', 'Permute', 'ZeroPadding1D', 'ZeroPadding2D'] Layer list File:converters/keras_to_hls.py Ligne: 98\n",
      "Interpreting Sequential\n",
      "InputLayer Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "SimpleRNN Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "Dense Layer name from json File: converters/keras_to_hls.py Ligne; 273\n",
      "Topology:\n",
      "Layer name: SimpleRNN_input, layer type: InputLayer, input shapes: [[None, 5, 1]], output shape: [None, 5, 1]\n",
      "{'class_name': 'SimpleRNN', 'config': {'name': 'SimpleRNN', 'trainable': True, 'batch_input_shape': [None, 5, 1], 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 8, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0}}\n",
      "[[None, 5, 1]]\n",
      "Layer name: SimpleRNN, layer type: SimpleRNN, input shapes: [[None, 5, 1]], output shape: [None, 5, 8]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 5, 8]], output shape: [None, 5, 1]\n",
      "Creating HLS model\n",
      "Model HLSModel\n",
      "config {'OutputDir': 'models/hls_models', 'ProjectName': 'myproject', 'Backend': 'Quartus', 'Part': '1SG280HU2F50E2VG', 'ClockPeriod': 5, 'IOType': 'io_parallel', 'HLSConfig': {'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'SimpleRNN_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, 'SimpleRNN': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>'}}, 'SimpleRNN_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, 'dense': {'Precision': {'weight': 'ap_fixed<6,4>', 'bias': 'ap_fixed<6,4>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}}}, 'KerasModel': <keras.engine.sequential.Sequential object at 0x7f3a2a26fbd0>, 'InputData': None, 'OutputPredictions': None}\n",
      "name\n",
      "self.flows ['quartus:ip'] File:hls_model.py Line: 180\n",
      "2 SELF_index, hls_layer, linha 997\n",
      "flows from __init__ quartus:ip File: hls_model.py Line: 324\n",
      "apply_flow quartus:ip File: hls_model.py Line 354\n",
      "flow_name quartus:ip File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b650> flow_map\n",
      "flow_optimizers [] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name optimize File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2b1a6190> flow_map\n",
      "flow_optimizers ['eliminate_linear_activation', 'fuse_consecutive_batch_normalization', 'fuse_batch_normalization', 'replace_multidimensional_dense_with_conv'] File: hls_model.py Line 366\n",
      "Flow requires: ['convert'] File:hls_model.py Line: 368\n",
      "flow_name convert File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2b25e110> flow_map\n",
      "flow_optimizers ['fuse_bias_add', 'remove_useless_transpose', 'output_rounding_saturation_mode', 'qkeras_factorize_alpha', 'extract_ternary_threshold', 'fuse_consecutive_batch_normalization'] File: hls_model.py Line 366\n",
      "fuse_bias_add Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "remove_useless_transpose Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "output_rounding_saturation_mode Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "qkeras_factorize_alpha Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "extract_ternary_threshold Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "eliminate_linear_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "replace_multidimensional_dense_with_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:init_layers File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b490> flow_map\n",
      "flow_optimizers ['quartus:init_base_layer', 'quartus:init_activation', 'quartus:init_dense', 'quartus:init_softmax'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize'] File:hls_model.py Line: 368\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:specific_types File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_dense', 'quartus:init_activation', 'quartus:init_base_layer'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b450> flow_map\n",
      "flow_optimizers ['quartus:transform_types'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:init_layers', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:apply_templates File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_dense', 'quartus:init_activation', 'quartus:init_base_layer'}, 'quartus:specific_types': {'quartus:transform_types'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b4d0> flow_map\n",
      "flow_optimizers ['quartus:lstm_config_template', 'quartus:lstm_function_template', 'quartus:simplernn_config_template', 'quartus:simplernn_function_template', 'quartus:dense_config_template', 'quartus:dense_function_template', 'quartus:batchnormalization_config_template', 'quartus:batchnormalization_function_template', 'quartus:activation_parametrizedactivation_prelu_config_template', 'quartus:softmax_config_template', 'quartus:activation_softmax_function_template', 'quartus:parametrizedactivation_function_template', 'quartus:prelu_function_template'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "none olha aqui\n",
      "apply_flow quartus:write File: hls_model.py Line 354\n",
      "flow_name quartus:write File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b550> flow_map\n",
      "flow_optimizers ['quartus:write_hls'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name optimize File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2b1a6190> flow_map\n",
      "flow_optimizers ['eliminate_linear_activation', 'fuse_consecutive_batch_normalization', 'fuse_batch_normalization', 'replace_multidimensional_dense_with_conv'] File: hls_model.py Line 366\n",
      "Flow requires: ['convert'] File:hls_model.py Line: 368\n",
      "flow_name convert File: hls_model.py Line 361\n",
      "applied_flows {} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2b25e110> flow_map\n",
      "flow_optimizers ['fuse_bias_add', 'remove_useless_transpose', 'output_rounding_saturation_mode', 'qkeras_factorize_alpha', 'extract_ternary_threshold', 'fuse_consecutive_batch_normalization'] File: hls_model.py Line 366\n",
      "fuse_bias_add Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "remove_useless_transpose Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "output_rounding_saturation_mode Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "qkeras_factorize_alpha Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "extract_ternary_threshold Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "eliminate_linear_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_consecutive_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "fuse_batch_normalization Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "replace_multidimensional_dense_with_conv Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:specific_types File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b450> flow_map\n",
      "flow_optimizers ['quartus:transform_types'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "flow_name quartus:init_layers File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set()} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b490> flow_map\n",
      "flow_optimizers ['quartus:init_base_layer', 'quartus:init_activation', 'quartus:init_dense', 'quartus:init_softmax'] File: hls_model.py Line 366\n",
      "Flow requires: ['optimize'] File:hls_model.py Line: 368\n",
      "quartus:init_base_layer Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_activation Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_dense Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:init_softmax Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:transform_types Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Flow requires: ['optimize', 'quartus:specific_types', 'quartus:apply_templates'] File:hls_model.py Line: 368\n",
      "flow_name quartus:apply_templates File: hls_model.py Line 361\n",
      "applied_flows {'convert': set(), 'optimize': set(), 'quartus:init_layers': {'quartus:init_dense', 'quartus:init_activation', 'quartus:init_base_layer'}, 'quartus:specific_types': {'quartus:transform_types'}} File: hls_model.py Line 362\n",
      "<hls4ml.model.flow.flow.Flow object at 0x7f3a2a36b4d0> flow_map\n",
      "flow_optimizers ['quartus:lstm_config_template', 'quartus:lstm_function_template', 'quartus:simplernn_config_template', 'quartus:simplernn_function_template', 'quartus:dense_config_template', 'quartus:dense_function_template', 'quartus:batchnormalization_config_template', 'quartus:batchnormalization_function_template', 'quartus:activation_parametrizedactivation_prelu_config_template', 'quartus:softmax_config_template', 'quartus:activation_softmax_function_template', 'quartus:parametrizedactivation_function_template', 'quartus:prelu_function_template'] File: hls_model.py Line 366\n",
      "Flow requires: ['quartus:init_layers'] File:hls_model.py Line: 368\n",
      "quartus:lstm_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:lstm_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:simplernn_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:dense_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:batchnormalization_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_parametrizedactivation_prelu_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:softmax_config_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:activation_softmax_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:parametrizedactivation_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "quartus:prelu_function_template Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "none olha aqui\n",
      "quartus:write_hls Get_Optimizer, optimizer/optimizer.py ligne: 168\n",
      "Writing HLS project\n",
      "layer2_t layer2_out[OUT_HEIGHT_2] def_cpp quartus writer linha 131\n",
      "layer3_t layer3_out[N_LAYER_3] def_cpp quartus writer linha 131\n",
      "Quartus_writer.py ligne 998\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from firmware/parameters.h:11,\n",
      "                 from firmware/myproject.h:33,\n",
      "                 from firmware/myproject.cpp:21:\n",
      "firmware/nnet_utils/simple_rnn_cell.h:2:10: fatal error: HLS/hls.h: No such file or directory\n",
      "    2 | #include \"HLS/hls.h\"\n",
      "      |          ^~~~~~~~~~~\n",
      "compilation terminated.\n",
      "In file included from firmware/parameters.h:11,\n",
      "                 from firmware/myproject.h:33,\n",
      "                 from myproject_bridge.cpp:4:\n",
      "firmware/nnet_utils/simple_rnn_cell.h:2:10: fatal error: HLS/hls.h: No such file or directory\n",
      "    2 | #include \"HLS/hls.h\"\n",
      "      |          ^~~~~~~~~~~\n",
      "compilation terminated.\n",
      "g++: error: myproject.o: No such file or directory\n",
      "g++: error: myproject_bridge.o: No such file or directory\n",
      "g++: fatal error: no input files\n",
      "compilation terminated.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "models/hls_models/firmware/myproject-EaCAfBFE.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25401/105374676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                             \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1SG280HU2F50E2VG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                             backend='Quartus')\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#y_qckeras = tmp_models[i].predict(x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hls4ml/hls4ml/hls4ml/hls4ml/model/graph.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mdlclose_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top_function_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_top_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: models/hls_models/firmware/myproject-EaCAfBFE.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "closs = []\n",
    "qcloss = []\n",
    "qchloss = []\n",
    "ptq_results = []\n",
    "\n",
    "bit_scale = []\n",
    "for i in range (bits_range):\n",
    "    conf = hls4ml.utils.config_from_keras_model( r_model, granularity='name')\n",
    "    conf['LayerName']['dense']['Precision']['weight'] = f'ap_fixed<{bit_lenghts(i)},{integer+1}>'\n",
    "    conf['LayerName']['dense']['Precision']['bias'] = f'ap_fixed<{bit_lenghts(i)},{integer+1}>'\n",
    "    conf['LayerName']['SimpleRNN']['Precision'] ={'weight' : f'ap_fixed<{bit_lenghts(i)},{integer+1}>', 'bias': f'ap_fixed<{bit_lenghts(i)},{integer+1}>' }\n",
    "\n",
    "    \n",
    "    print(conf)\n",
    "        \n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(r_model,\n",
    "                                                            hls_config=conf,\n",
    "                                                            output_dir='models/hls_models',\n",
    "                                                            part='1SG280HU2F50E2VG',\n",
    "                                                            backend='Quartus')\n",
    "    hls_model.compile()\n",
    "\n",
    "    #y_qckeras = tmp_models[i].predict(x_test)\n",
    "    y_qchls = hls_model.predict(x_test.reshape(x_test.shape[0],1))\n",
    "    ptq_results.append(y_qchls)\n",
    "    y_keras = r_model.predict(x_test)\n",
    "    closs.append(mse(y_test, y_keras))\n",
    "    #qcloss.append(mse(y_test, y_qckeras))\n",
    "    qchloss.append(mse(y_test, y_qchls))\n",
    "    bit_scale.append(bit_lenghts(i))\n",
    "    plt.figure()\n",
    "    #plt.plot(y_qckeras, '--', linewidth=2)\n",
    "    plt.plot(y_qchls)\n",
    "    plt.plot(y_test)    \n",
    "    plt.legend(['keras+hls', 'keras'])\n",
    "    plt.title(f'PTQ : bitwidths of ({bit_lenghts(i)},{integer},0,1)')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bit_scale, qchloss)\n",
    "plt.xlabel('bits')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'PTQ : bitwidths of (x,{integer},0,1), {nbr_epoch} epochs')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, \n",
    "'LayerName': {'simple_rnn_input': {'Precision': {'result': 'ap_fixed<16,6>'}}, \n",
    "            'simple_rnn': {'Precision': 'ap_fixed<16,6>'}, \n",
    "            'simple_rnn_tanh': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}, \n",
    "            'dense': {'Precision': {'weight': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}, \n",
    "            'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS CONVERSION of the QKeras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
