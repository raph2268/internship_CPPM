{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini RNN  adapt for FPGA for very high frequency physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LHC, ATLAS AND Liquid Argon Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LHC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The CERN is operating the LHC (Large Hadron Collider). The LHC is the end of several particle accelerators and can accelerate particles to 7-8 GeV. There are four collision points on the LHC, ATLAS, CMS, LHCb and ALICE. The objective is to collide bench of particles into each other and create for a really short instant a really heavy particle (as E=mc²). Those heavy particles are so instable that it is not possible for us to detect them, however they disintegrate into smaller particles from which we can establish equation and deduct what was the big particle. \n",
    "\n",
    "The LHC is in constant improvement. In June, Run 3 of the LHC will occur. For this run, LHC is still on his first phase of development. \n",
    "But in the beginning in 2027, the HL-LHC will be hold. In this phase, LHC will become HL-LHC for High Luminosity. In fact, global improvement on the accelerator will give the possibility to greatly increase the number of particle crossing each other at each bench, this way, increasing the number of collision and data. \n",
    "\n",
    "The increased of the data amount has to be taken in account by the detector, this is why each of ATLAS detector acquisition system have to be improved. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ATLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPPM is associated with ATLAS detector which is a photon-photon detector.  Atlas is built like a Russian-doll, with detector surrounding each other.\n",
    "\n",
    "Beams of particles from the LHC collide at the centre of the ATLAS detector making collision debris in the form of new particles, which fly out from the collision point in all directions. Six different detecting subsystems arranged in layers around the collision point record the paths, momentum, and energy of the particles, allowing them to be individually identified. A huge magnet system bends the paths of charged particles so that their momenta can be measured.\n",
    "\n",
    "The interactions in the ATLAS detectors create an enormous flow of data. To digest the data, ATLAS uses an advanced “trigger” system to tell the detector which events to record and which to ignore. Complex data-acquisition and computing systems are then used to analyse the collision events recorded. At 46 m long, 25 m high and 25 m wide, the 7000-tonne ATLAS detector is the largest volume particle detector ever constructed. It sits in a cavern 100 m below ground near the main CERN site, close to the village of Meyrin in Switzerland.\n",
    "\n",
    "The project I will work on is dedicated for the Liquid Argon calorimeter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liquid Argon Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LAr is a calorimeter, it measures the energy. \n",
    "\n",
    "So how does the LAr acquisition system works ?  First, it is in constant improvement, and to be sure that the detector is always working, ATLAS team are always keeping the oldest working version on while testing a new version.\n",
    "\n",
    "So basically the detector is composed of two plates with high voltage set inside a bath of Argon. The system is simple, every a particle goes across the bath, they transform Argon into ions, which create current in the system that can be measured. The more energy the particle has, the more the intensity is high. From the highest energy pick detected during the passage of the particle, we can deduce which particle it is. \n",
    "\n",
    "Now what is happening is that the acquisition system has to sample at 40MHz in order to follow the crazy rate of 1 collision every 25ns. This data can be stored for a short time on a buffer, but need to be sorted as soon as possible. To select the interesting part, a trigger is used. This means that we select only five inputs, that sums up the whole passage of the particle. Those five inputs are currently selected via an OF, this OF is encoded on FPGA. \n",
    "\n",
    "The current system is working well but struggles when two particles are crossing the detectors in the same time. \n",
    "If this is happening, a pile up phenomena occurs, and instead of having a clear pick of energy to detect, the two energies are mixed up by the detector and the trigger don’t know anymore how to work.\n",
    "\n",
    "However, with the HL LHC, those events that were by the past rare, will become very probable. \n",
    "\n",
    "The main mission of the team is then to create a system that first can detect a pile up event, and then can evaluate the energy of each by separating the two events. \n",
    "\n",
    "To do so, RNN and CNN are being tested but those two have to fit on the FPGA montage that will be implemented at the end. \n",
    "\n",
    "The team at CPPM is focusing on the RNN work. They first came with an LSTM cell that repeat itself, this was unfortunately really efficient but is not possibly implantable on FPGA. They are now on vanilla cell but with a sliding windows. This solution seems to be more optimized but is still too big for FPGA. \n",
    "\n",
    "To fit the FPGA, what has already been done, is that they are using fixed quantized number instead of 32 bits long float number in the original code, but then efficiency is lost. \n",
    "\n",
    "What they want me to do is now, instead of taking a neural network trained and quantized it during the implementation of the FPGA, they want me to train a neural network already quantized. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network (NN), is an interconnected group of natural or artificial neurons that uses a mathematical or computational model for information processing based on a connectionistic approach to computation. In most cases an NN is an adaptive system that changes its structure based on external or internal information that flows through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structure of the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NN are composed of multiples layers. Each network is composed of one input layer, one output layer, and most of the time several 'hiddens' layers. \n",
    "\n",
    "These layers are composed of cells/units/nodes. Each of this nodes takes inputs and passes them into a function named the activation function. The activation function is the same for the whole layer, but in each unit, the input is implemented with differents weights. \n",
    "\n",
    "Those weights shape the input of the activation function and so the output as they help determine the importance of any given variable, with larger ones contributing more significantly to the output compared to other inputs.\n",
    "\n",
    "\n",
    "The outputs of the node is then going to all the cells of the next layer and this is how the data go throught the network until it reaches the output layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are shaped all along the network by the successives activations functions. Those functions are themselves altered by the weights. \n",
    "Now what is interesting is to see how those weights are chosen to get to the good outputs.\n",
    "In fact those weigths are the final step of a long adjustement call the training.\n",
    "\n",
    "During this step, the weights are optimized to maximize the neural network's accuracy.\n",
    "\n",
    "Although, the weights are highly interdependent, indeed, the choice of one weight will have direct consequences on every nodes of the next layer and so on evry weights of n+2 layer. \n",
    "So we can not obtain the best weight by optimizing them one by one. Then we need to find the best combinaison of weight.\n",
    "\n",
    "For simple problem we can use linear regression, where we try to create line that passes the closest to the most points : this is measured with the loss function that in this case calculate the mean distance between the line and the points. \n",
    "Then we can use gradient descent to find one point that minimize enought this loss function. \n",
    "\n",
    "Although, most NN problems don't have linear problem. This is why we are using nonlinear activation function. \n",
    "This nonlinearity means that the parameters do not act independantly of each other in influencing the shape of the loss function.\n",
    "\n",
    "The loss will not have anymore a linear curve that allows us to find out the minimal just by running gradient descent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, the way gradient descent works is similar to the mountain climber analogy, were the climber in the dark check for every direction and choose the one that seems to go the most down. \n",
    "We first start with a random guess and then step by step we repeat the same process until we found the deepest point.\n",
    "Then, what need to be decided is how large the step have to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests on RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Keras model I want to determine the impact of the following features :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patiences Early stopping and patiences for Reduce LR :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the patience will let more chances to the model to improve find a way out of a local minimal.\n",
    "Reducing the patience reduces the training time.\n",
    "\n",
    "From what I oserved it seems that once the system is stuck at 5 epochs without improving, it is never improving more.\n",
    "The patiences for early stopping a have to be related to the patience of the Reduce LR. \n",
    "It has to be greater so that, if not reduce LR will never be used.\n",
    "\n",
    "Indeed the patience for reduce lr is waiting for the model to  be stucked somewhere it can't improved to reduce the learning rate and check to improved it.\n",
    "\n",
    "I am testing to set those to 8 and 5, this allows the model to be stuck during 8 epochs, at the fifth one, he is reducing the lr, if nothings happened after three more epochs, then we stop the learning.\n",
    "\n",
    "Regarding the reference model, trained on a fixed 0.0001 lr, we cna say that \n",
    "After observations, it seems that the threshold to get to anew "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate here is not this important as he is evolving with the reduced lr callback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to generate the ROOTs plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this and generate a .ROOT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import nnDumper_standalone\n",
    "importlib.reload(nnDumper_standalone)\n",
    "\n",
    "ds = DataShaper.from_h5(\"data/rdgap_mu140.h5\")\n",
    "x, x_val, x_test, y, y_val, y_test = ds()\n",
    "m_t = 16\n",
    "model = qkeras.utils.load_qmodel('path_to_model')\n",
    "dump_preds = nnDumper_standalone.dumper(start = 999997, name = \"test\", bt_len=80)\n",
    "\n",
    "dump_preds.set_data(true = ds.hit, data = ds.dig, sig = ds.sig, ofmax = ds.ofmax)\n",
    "\n",
    "dump_preds.set_preds('type', m_t*model.predict(x_test).flatten())\n",
    "\n",
    "dump_preds.runme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, resolution_drawer_with_gaps.C define the type of your model and set a label to it. \n",
    "You also need to file the path of the input (look for 'infiles'). \n",
    "It is also required to change the file to compare (just below the infile path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then setup the environement by running those :\n",
    "\n",
    "export ATLAS_LOCAL_ROOT_BASE=/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase\n",
    "alias setupATLAS='source ${ATLAS_LOCAL_ROOT_BASE}/user/atlasLocalSetup.sh'\n",
    "export ALRB_rootVersion=6.14.04-x86_64-slc6-gcc62-opt\n",
    "\n",
    "setupATLAS\n",
    "lsetup root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the plots by running these : \n",
    "`echo root-config --cflags --glibs` | sed s/\" -std=c++11\"//g\n",
    "g++ resolution_drawer_with_gaps.C -o resdrawer -lm -g -Wall ADD_HERE_OUTPUT_OF_PREVIOUS_LINE\n",
    "./resdrawer 2>&1 | tee log.resdrawer\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "978a78fee93b9f75d300423e922c5a4da2d32993b15c09db9f940a22d4b78528"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('hls4ml-tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
